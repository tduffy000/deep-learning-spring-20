{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| This data was extracted from the census bureau database found at\r\n",
      "| http://www.census.gov/ftp/pub/DES/www/welcome.html\r\n",
      "| Donor: Ronny Kohavi and Barry Becker,\r\n",
      "|        Data Mining and Visualization\r\n",
      "|        Silicon Graphics.\r\n",
      "|        e-mail: ronnyk@sgi.com for questions.\r\n",
      "| Split into train-test using MLC++ GenCVFiles (2/3, 1/3 random).\r\n",
      "| 48842 instances, mix of continuous and discrete    (train=32561, test=16281)\r\n",
      "| 45222 if instances with unknown values are removed (train=30162, test=15060)\r\n",
      "| Duplicate or conflicting instances : 6\r\n",
      "| Class probabilities for adult.all file\r\n",
      "| Probability for the label '>50K'  : 23.93% / 24.78% (without unknowns)\r\n",
      "| Probability for the label '<=50K' : 76.07% / 75.22% (without unknowns)\r\n",
      "|\r\n",
      "| Extraction was done by Barry Becker from the 1994 Census database.  A set of\r\n",
      "|   reasonably clean records was extracted using the following conditions:\r\n",
      "|   ((AAGE>16) && (AGI>100) && (AFNLWGT>1)&& (HRSWK>0))\r\n",
      "|\r\n",
      "| Prediction task is to determine whether a person makes over 50K\r\n",
      "| a year.\r\n",
      "|\r\n",
      "| First cited in:\r\n",
      "| @inproceedings{kohavi-nbtree,\r\n",
      "|    author={Ron Kohavi},\r\n",
      "|    title={Scaling Up the Accuracy of Naive-Bayes Classifiers: a\r\n",
      "|           Decision-Tree Hybrid},\r\n",
      "|    booktitle={Proceedings of the Second International Conference on\r\n",
      "|               Knowledge Discovery and Data Mining},\r\n",
      "|    year = 1996,\r\n",
      "|    pages={to appear}}\r\n",
      "|\r\n",
      "| Error Accuracy reported as follows, after removal of unknowns from\r\n",
      "|    train/test sets):\r\n",
      "|    C4.5       : 84.46+-0.30\r\n",
      "|    Naive-Bayes: 83.88+-0.30\r\n",
      "|    NBTree     : 85.90+-0.28\r\n",
      "|\r\n",
      "|\r\n",
      "| Following algorithms were later run with the following error rates,\r\n",
      "|    all after removal of unknowns and using the original train/test split.\r\n",
      "|    All these numbers are straight runs using MLC++ with default values.\r\n",
      "|\r\n",
      "|    Algorithm               Error\r\n",
      "| -- ----------------        -----\r\n",
      "| 1  C4.5                    15.54\r\n",
      "| 2  C4.5-auto               14.46\r\n",
      "| 3  C4.5 rules              14.94\r\n",
      "| 4  Voted ID3 (0.6)         15.64\r\n",
      "| 5  Voted ID3 (0.8)         16.47\r\n",
      "| 6  T2                      16.84\r\n",
      "| 7  1R                      19.54\r\n",
      "| 8  NBTree                  14.10\r\n",
      "| 9  CN2                     16.00\r\n",
      "| 10 HOODG                   14.82\r\n",
      "| 11 FSS Naive Bayes         14.05\r\n",
      "| 12 IDTM (Decision table)   14.46\r\n",
      "| 13 Naive-Bayes             16.12\r\n",
      "| 14 Nearest-neighbor (1)    21.42\r\n",
      "| 15 Nearest-neighbor (3)    20.35\r\n",
      "| 16 OC1                     15.04\r\n",
      "| 17 Pebls                   Crashed.  Unknown why (bounds WERE increased)\r\n",
      "|\r\n",
      "| Conversion of original data as follows:\r\n",
      "| 1. Discretized agrossincome into two ranges with threshold 50,000.\r\n",
      "| 2. Convert U.S. to US to avoid periods.\r\n",
      "| 3. Convert Unknown to \"?\"\r\n",
      "| 4. Run MLC++ GenCVFiles to generate data,test.\r\n",
      "|\r\n",
      "| Description of fnlwgt (final weight)\r\n",
      "|\r\n",
      "| The weights on the CPS files are controlled to independent estimates of the\r\n",
      "| civilian noninstitutional population of the US.  These are prepared monthly\r\n",
      "| for us by Population Division here at the Census Bureau.  We use 3 sets of\r\n",
      "| controls.\r\n",
      "|  These are:\r\n",
      "|          1.  A single cell estimate of the population 16+ for each state.\r\n",
      "|          2.  Controls for Hispanic Origin by age and sex.\r\n",
      "|          3.  Controls by Race, age and sex.\r\n",
      "|\r\n",
      "| We use all three sets of controls in our weighting program and \"rake\" through\r\n",
      "| them 6 times so that by the end we come back to all the controls we used.\r\n",
      "|\r\n",
      "| The term estimate refers to population totals derived from CPS by creating\r\n",
      "| \"weighted tallies\" of any specified socio-economic characteristics of the\r\n",
      "| population.\r\n",
      "|\r\n",
      "| People with similar demographic characteristics should have\r\n",
      "| similar weights.  There is one important caveat to remember\r\n",
      "| about this statement.  That is that since the CPS sample is\r\n",
      "| actually a collection of 51 state samples, each with its own\r\n",
      "| probability of selection, the statement only applies within\r\n",
      "| state.\r\n",
      "\r\n",
      "\r\n",
      ">50K, <=50K.\r\n",
      "\r\n",
      "age: continuous.\r\n",
      "workclass: Private, Self-emp-not-inc, Self-emp-inc, Federal-gov, Local-gov, State-gov, Without-pay, Never-worked.\r\n",
      "fnlwgt: continuous.\r\n",
      "education: Bachelors, Some-college, 11th, HS-grad, Prof-school, Assoc-acdm, Assoc-voc, 9th, 7th-8th, 12th, Masters, 1st-4th, 10th, Doctorate, 5th-6th, Preschool.\r\n",
      "education-num: continuous.\r\n",
      "marital-status: Married-civ-spouse, Divorced, Never-married, Separated, Widowed, Married-spouse-absent, Married-AF-spouse.\r\n",
      "occupation: Tech-support, Craft-repair, Other-service, Sales, Exec-managerial, Prof-specialty, Handlers-cleaners, Machine-op-inspct, Adm-clerical, Farming-fishing, Transport-moving, Priv-house-serv, Protective-serv, Armed-Forces.\r\n",
      "relationship: Wife, Own-child, Husband, Not-in-family, Other-relative, Unmarried.\r\n",
      "race: White, Asian-Pac-Islander, Amer-Indian-Eskimo, Other, Black.\r\n",
      "sex: Female, Male.\r\n",
      "capital-gain: continuous.\r\n",
      "capital-loss: continuous.\r\n",
      "hours-per-week: continuous.\r\n",
      "native-country: United-States, Cambodia, England, Puerto-Rico, Canada, Germany, Outlying-US(Guam-USVI-etc), India, Japan, Greece, South, China, Cuba, Iran, Honduras, Philippines, Italy, Poland, Jamaica, Vietnam, Mexico, Portugal, Ireland, France, Dominican-Republic, Laos, Ecuador, Taiwan, Haiti, Columbia, Hungary, Guatemala, Nicaragua, Scotland, Thailand, Yugoslavia, El-Salvador, Trinadad&Tobago, Peru, Hong, Holand-Netherlands.\r\n"
     ]
    }
   ],
   "source": [
    "!curl -X GET http://archive.ics.uci.edu/ml/machine-learning-databases/adult/adult.names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 270,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = ['age', 'workclass', 'fnlwgt', 'education', 'education-num','marital-status','occupation','relationship','race','sex','capital-gain','capital-loss','hours-per-week','native-country','target'] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 271,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('adult.data', names=features, header=None,index_col=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 272,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>workclass</th>\n",
       "      <th>fnlwgt</th>\n",
       "      <th>education</th>\n",
       "      <th>education-num</th>\n",
       "      <th>marital-status</th>\n",
       "      <th>occupation</th>\n",
       "      <th>relationship</th>\n",
       "      <th>race</th>\n",
       "      <th>sex</th>\n",
       "      <th>capital-gain</th>\n",
       "      <th>capital-loss</th>\n",
       "      <th>hours-per-week</th>\n",
       "      <th>native-country</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>39</td>\n",
       "      <td>State-gov</td>\n",
       "      <td>77516</td>\n",
       "      <td>Bachelors</td>\n",
       "      <td>13</td>\n",
       "      <td>Never-married</td>\n",
       "      <td>Adm-clerical</td>\n",
       "      <td>Not-in-family</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>2174</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>50</td>\n",
       "      <td>Self-emp-not-inc</td>\n",
       "      <td>83311</td>\n",
       "      <td>Bachelors</td>\n",
       "      <td>13</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Exec-managerial</td>\n",
       "      <td>Husband</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>13</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>38</td>\n",
       "      <td>Private</td>\n",
       "      <td>215646</td>\n",
       "      <td>HS-grad</td>\n",
       "      <td>9</td>\n",
       "      <td>Divorced</td>\n",
       "      <td>Handlers-cleaners</td>\n",
       "      <td>Not-in-family</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>53</td>\n",
       "      <td>Private</td>\n",
       "      <td>234721</td>\n",
       "      <td>11th</td>\n",
       "      <td>7</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Handlers-cleaners</td>\n",
       "      <td>Husband</td>\n",
       "      <td>Black</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>28</td>\n",
       "      <td>Private</td>\n",
       "      <td>338409</td>\n",
       "      <td>Bachelors</td>\n",
       "      <td>13</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Prof-specialty</td>\n",
       "      <td>Wife</td>\n",
       "      <td>Black</td>\n",
       "      <td>Female</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>Cuba</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   age          workclass  fnlwgt   education  education-num  \\\n",
       "0   39          State-gov   77516   Bachelors             13   \n",
       "1   50   Self-emp-not-inc   83311   Bachelors             13   \n",
       "2   38            Private  215646     HS-grad              9   \n",
       "3   53            Private  234721        11th              7   \n",
       "4   28            Private  338409   Bachelors             13   \n",
       "\n",
       "        marital-status          occupation    relationship    race      sex  \\\n",
       "0        Never-married        Adm-clerical   Not-in-family   White     Male   \n",
       "1   Married-civ-spouse     Exec-managerial         Husband   White     Male   \n",
       "2             Divorced   Handlers-cleaners   Not-in-family   White     Male   \n",
       "3   Married-civ-spouse   Handlers-cleaners         Husband   Black     Male   \n",
       "4   Married-civ-spouse      Prof-specialty            Wife   Black   Female   \n",
       "\n",
       "   capital-gain  capital-loss  hours-per-week  native-country  target  \n",
       "0          2174             0              40   United-States   <=50K  \n",
       "1             0             0              13   United-States   <=50K  \n",
       "2             0             0              40   United-States   <=50K  \n",
       "3             0             0              40   United-States   <=50K  \n",
       "4             0             0              40            Cuba   <=50K  "
      ]
     },
     "execution_count": 272,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can drop `relationship` which is somewhat of a confounding variable and tied up in `marital-status` as well. `native-country` just widens our data too much, so let's shift it to be either `US` or `foreign`. Also let's group together `workclass` for the `govt` and `self` employed individuals."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 273,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop(['fnlwgt', 'relationship','education'],axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 274,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([' United-States', ' Cuba', ' Jamaica', ' India', ' ?', ' Mexico',\n",
       "       ' South', ' Puerto-Rico', ' Honduras', ' England', ' Canada',\n",
       "       ' Germany', ' Iran', ' Philippines', ' Italy', ' Poland',\n",
       "       ' Columbia', ' Cambodia', ' Thailand', ' Ecuador', ' Laos',\n",
       "       ' Taiwan', ' Haiti', ' Portugal', ' Dominican-Republic',\n",
       "       ' El-Salvador', ' France', ' Guatemala', ' China', ' Japan',\n",
       "       ' Yugoslavia', ' Peru', ' Outlying-US(Guam-USVI-etc)', ' Scotland',\n",
       "       ' Trinadad&Tobago', ' Greece', ' Nicaragua', ' Vietnam', ' Hong',\n",
       "       ' Ireland', ' Hungary', ' Holand-Netherlands'], dtype=object)"
      ]
     },
     "execution_count": 274,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# convert native-country\n",
    "df['native-country'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 275,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['native-country'] = df['native-country'].apply(lambda s: 'US' if s == 'United-States' else 'Foreign')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 276,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>workclass</th>\n",
       "      <th>education-num</th>\n",
       "      <th>marital-status</th>\n",
       "      <th>occupation</th>\n",
       "      <th>race</th>\n",
       "      <th>sex</th>\n",
       "      <th>capital-gain</th>\n",
       "      <th>capital-loss</th>\n",
       "      <th>hours-per-week</th>\n",
       "      <th>native-country</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>39</td>\n",
       "      <td>State-gov</td>\n",
       "      <td>13</td>\n",
       "      <td>Never-married</td>\n",
       "      <td>Adm-clerical</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>2174</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>Foreign</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>50</td>\n",
       "      <td>Self-emp-not-inc</td>\n",
       "      <td>13</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Exec-managerial</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>13</td>\n",
       "      <td>Foreign</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>38</td>\n",
       "      <td>Private</td>\n",
       "      <td>9</td>\n",
       "      <td>Divorced</td>\n",
       "      <td>Handlers-cleaners</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>Foreign</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>53</td>\n",
       "      <td>Private</td>\n",
       "      <td>7</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Handlers-cleaners</td>\n",
       "      <td>Black</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>Foreign</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>28</td>\n",
       "      <td>Private</td>\n",
       "      <td>13</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Prof-specialty</td>\n",
       "      <td>Black</td>\n",
       "      <td>Female</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>Foreign</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   age          workclass  education-num       marital-status  \\\n",
       "0   39          State-gov             13        Never-married   \n",
       "1   50   Self-emp-not-inc             13   Married-civ-spouse   \n",
       "2   38            Private              9             Divorced   \n",
       "3   53            Private              7   Married-civ-spouse   \n",
       "4   28            Private             13   Married-civ-spouse   \n",
       "\n",
       "           occupation    race      sex  capital-gain  capital-loss  \\\n",
       "0        Adm-clerical   White     Male          2174             0   \n",
       "1     Exec-managerial   White     Male             0             0   \n",
       "2   Handlers-cleaners   White     Male             0             0   \n",
       "3   Handlers-cleaners   Black     Male             0             0   \n",
       "4      Prof-specialty   Black   Female             0             0   \n",
       "\n",
       "   hours-per-week native-country  target  \n",
       "0              40        Foreign   <=50K  \n",
       "1              13        Foreign   <=50K  \n",
       "2              40        Foreign   <=50K  \n",
       "3              40        Foreign   <=50K  \n",
       "4              40        Foreign   <=50K  "
      ]
     },
     "execution_count": 276,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 277,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([' State-gov', ' Self-emp-not-inc', ' Private', ' Federal-gov',\n",
       "       ' Local-gov', ' ?', ' Self-emp-inc', ' Without-pay',\n",
       "       ' Never-worked'], dtype=object)"
      ]
     },
     "execution_count": 277,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['workclass'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 278,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_workclass(s):\n",
    "    if s.endswith('gov'):\n",
    "        return 'govt'\n",
    "    if s.startswith(' Self'):\n",
    "        return 'self'\n",
    "    if s.endswith('Private'):\n",
    "        return 'private'\n",
    "    if s == ' Without-pay':\n",
    "        return 'volunteer'\n",
    "    if s == ' Never-worked':\n",
    "        return 'never'\n",
    "    else: # case of ?\n",
    "        return 'unknown'\n",
    "df['workclass'] = df['workclass'].apply(clean_workclass)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 279,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>workclass</th>\n",
       "      <th>education-num</th>\n",
       "      <th>marital-status</th>\n",
       "      <th>occupation</th>\n",
       "      <th>race</th>\n",
       "      <th>sex</th>\n",
       "      <th>capital-gain</th>\n",
       "      <th>capital-loss</th>\n",
       "      <th>hours-per-week</th>\n",
       "      <th>native-country</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>39</td>\n",
       "      <td>govt</td>\n",
       "      <td>13</td>\n",
       "      <td>Never-married</td>\n",
       "      <td>Adm-clerical</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>2174</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>Foreign</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>50</td>\n",
       "      <td>self</td>\n",
       "      <td>13</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Exec-managerial</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>13</td>\n",
       "      <td>Foreign</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>38</td>\n",
       "      <td>private</td>\n",
       "      <td>9</td>\n",
       "      <td>Divorced</td>\n",
       "      <td>Handlers-cleaners</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>Foreign</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>53</td>\n",
       "      <td>private</td>\n",
       "      <td>7</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Handlers-cleaners</td>\n",
       "      <td>Black</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>Foreign</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>28</td>\n",
       "      <td>private</td>\n",
       "      <td>13</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Prof-specialty</td>\n",
       "      <td>Black</td>\n",
       "      <td>Female</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>Foreign</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   age workclass  education-num       marital-status          occupation  \\\n",
       "0   39      govt             13        Never-married        Adm-clerical   \n",
       "1   50      self             13   Married-civ-spouse     Exec-managerial   \n",
       "2   38   private              9             Divorced   Handlers-cleaners   \n",
       "3   53   private              7   Married-civ-spouse   Handlers-cleaners   \n",
       "4   28   private             13   Married-civ-spouse      Prof-specialty   \n",
       "\n",
       "     race      sex  capital-gain  capital-loss  hours-per-week native-country  \\\n",
       "0   White     Male          2174             0              40        Foreign   \n",
       "1   White     Male             0             0              13        Foreign   \n",
       "2   White     Male             0             0              40        Foreign   \n",
       "3   Black     Male             0             0              40        Foreign   \n",
       "4   Black   Female             0             0              40        Foreign   \n",
       "\n",
       "   target  \n",
       "0   <=50K  \n",
       "1   <=50K  \n",
       "2   <=50K  \n",
       "3   <=50K  \n",
       "4   <=50K  "
      ]
     },
     "execution_count": 279,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## To features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [],
   "source": [
    "target = df.target\n",
    "X = pd.get_dummies(df.drop(['target'], axis=1)).values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(32561, 41)"
      ]
     },
     "execution_count": 194,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(32561,)"
      ]
     },
     "execution_count": 195,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = np.array([int(i) for i in target.values == ' <=50K'])\n",
    "y.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split, KFold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.1.0'"
      ]
     },
     "execution_count": 197,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "tf.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=.25)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Neural Network\n",
    "#### Base Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.models.Sequential([\n",
    "    tf.keras.layers.Dense(32, activation='relu'),\n",
    "    tf.keras.layers.Dense(64, activation='relu'),\n",
    "    tf.keras.layers.Dense(32, activation='relu'),\n",
    "    tf.keras.layers.Dense(1, activation='sigmoid')\n",
    "])\n",
    "metrics = [\n",
    "    tf.keras.metrics.AUC(),\n",
    "    tf.keras.metrics.Accuracy(),\n",
    "    tf.keras.metrics.Precision(),\n",
    "    tf.keras.metrics.Recall()\n",
    "]\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics = metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 24420 samples\n",
      "Epoch 1/10\n",
      "24420/24420 [==============================] - 9s 368us/sample - loss: 3.7205 - auc: 0.7656 - accuracy: 0.0313 - precision: 0.8313 - recall: 0.9178\n",
      "Epoch 2/10\n",
      "24420/24420 [==============================] - 11s 463us/sample - loss: 1.0787 - auc: 0.8466 - accuracy: 0.0161 - precision: 0.8610 - recall: 0.9168\n",
      "Epoch 3/10\n",
      "24420/24420 [==============================] - 13s 523us/sample - loss: 0.8602 - auc: 0.8514 - accuracy: 0.0141 - precision: 0.8594 - recall: 0.9119\n",
      "Epoch 4/10\n",
      "24420/24420 [==============================] - 12s 497us/sample - loss: 0.5807 - auc: 0.8718 - accuracy: 0.0088 - precision: 0.8646 - recall: 0.9154\n",
      "Epoch 5/10\n",
      "24420/24420 [==============================] - 13s 516us/sample - loss: 0.3961 - auc: 0.8809 - accuracy: 0.0020 - precision: 0.8655 - recall: 0.9221\n",
      "Epoch 6/10\n",
      "24420/24420 [==============================] - 13s 529us/sample - loss: 0.3863 - auc: 0.8838 - accuracy: 0.0029 - precision: 0.8663 - recall: 0.9231\n",
      "Epoch 7/10\n",
      "24420/24420 [==============================] - 13s 538us/sample - loss: 0.3450 - auc: 0.8893 - accuracy: 0.0029 - precision: 0.8659 - recall: 0.9293\n",
      "Epoch 8/10\n",
      "24420/24420 [==============================] - 14s 559us/sample - loss: 0.3643 - auc: 0.8731 - accuracy: 0.0015 - precision: 0.8563 - recall: 0.9291\n",
      "Epoch 9/10\n",
      "24420/24420 [==============================] - 15s 595us/sample - loss: 0.3917 - auc: 0.8655 - accuracy: 1.2285e-04 - precision: 0.8458 - recall: 0.9274\n",
      "Epoch 10/10\n",
      "24420/24420 [==============================] - 13s 546us/sample - loss: 0.3705 - auc: 0.8672 - accuracy: 0.0000e+00 - precision: 0.8361 - recall: 0.9314\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f48e582b250>"
      ]
     },
     "execution_count": 253,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train, y_train, batch_size=16, epochs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot stuff\n",
    "# just remember that | Class probabilities for adult.all file\n",
    "# | Probability for the label '>50K'  : 23.93% / 24.78% (without unknowns)\n",
    "# | Probability for the label '<=50K' : 76.07% / 75.22% (without unknowns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### K-Fold Cross Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "activation_functions = ['sigmoid', '']\n",
    "weight_inits = ['']\n",
    "num_layers = [i for i in range(2,5)]\n",
    "hidden_layers = [2 ** i for i in range(5,7)]\n",
    "\n",
    "models = []\n",
    "for _ in range(5):\n",
    "    model = tf.keras.models.Sequential()\n",
    "    layers = [ tf.keras.layers.Dense(random.choice(hidden_layers), activation='relu') for _ in range(random.choice(num_layers)) ]\n",
    "    for l in layers:\n",
    "        model.add(l)\n",
    "    output_layer = tf.keras.layers.Dense(1, activation='sigmoid')\n",
    "    model.add(output_layer)\n",
    "    model.compile(optimizer='adam', loss='binary_crossentropy', metrics = metrics)\n",
    "    models.append(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8141/8141 [==============================] - 2s 300us/sample - loss: 0.3497 - auc: 0.8901 - accuracy: 0.0000e+00 - precision: 0.8894 - recall: 0.8821\n",
      "8141/8141 [==============================] - 2s 295us/sample - loss: 0.3479 - auc: 0.8872 - accuracy: 0.0000e+00 - precision: 0.8892 - recall: 0.8803\n",
      "8141/8141 [==============================] - 4s 532us/sample - loss: 0.3299 - auc: 0.9052 - accuracy: 0.0000e+00 - precision: 0.8713 - recall: 0.9214\n",
      "8141/8141 [==============================] - 2s 298us/sample - loss: 0.3463 - auc: 0.8894 - accuracy: 0.0000e+00 - precision: 0.8844 - recall: 0.8876\n",
      "8141/8141 [==============================] - 3s 319us/sample - loss: 0.3505 - auc: 0.8882 - accuracy: 0.0000e+00 - precision: 0.8681 - recall: 0.9060\n"
     ]
    }
   ],
   "source": [
    "# let's first ensure our random search worked\n",
    "for model in models:\n",
    "    model.fit(X_train, y_train, batch_size=16, epochs=10, verbose=0)\n",
    "    model.evaluate(X_test, y_test, batch_size=16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_29\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_98 (Dense)             multiple                  1344      \n",
      "_________________________________________________________________\n",
      "dense_99 (Dense)             multiple                  1056      \n",
      "_________________________________________________________________\n",
      "dense_100 (Dense)            multiple                  2112      \n",
      "_________________________________________________________________\n",
      "dense_101 (Dense)            multiple                  65        \n",
      "=================================================================\n",
      "Total params: 4,577\n",
      "Trainable params: 4,577\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Model: \"sequential_30\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_102 (Dense)            multiple                  2688      \n",
      "_________________________________________________________________\n",
      "dense_103 (Dense)            multiple                  2080      \n",
      "_________________________________________________________________\n",
      "dense_104 (Dense)            multiple                  1056      \n",
      "_________________________________________________________________\n",
      "dense_105 (Dense)            multiple                  33        \n",
      "=================================================================\n",
      "Total params: 5,857\n",
      "Trainable params: 5,857\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Model: \"sequential_31\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_106 (Dense)            multiple                  1344      \n",
      "_________________________________________________________________\n",
      "dense_107 (Dense)            multiple                  1056      \n",
      "_________________________________________________________________\n",
      "dense_108 (Dense)            multiple                  1056      \n",
      "_________________________________________________________________\n",
      "dense_109 (Dense)            multiple                  33        \n",
      "=================================================================\n",
      "Total params: 3,489\n",
      "Trainable params: 3,489\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Model: \"sequential_32\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_110 (Dense)            multiple                  2688      \n",
      "_________________________________________________________________\n",
      "dense_111 (Dense)            multiple                  2080      \n",
      "_________________________________________________________________\n",
      "dense_112 (Dense)            multiple                  2112      \n",
      "_________________________________________________________________\n",
      "dense_113 (Dense)            multiple                  65        \n",
      "=================================================================\n",
      "Total params: 6,945\n",
      "Trainable params: 6,945\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Model: \"sequential_33\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_114 (Dense)            multiple                  1344      \n",
      "_________________________________________________________________\n",
      "dense_115 (Dense)            multiple                  2112      \n",
      "_________________________________________________________________\n",
      "dense_116 (Dense)            multiple                  4160      \n",
      "_________________________________________________________________\n",
      "dense_117 (Dense)            multiple                  2080      \n",
      "_________________________________________________________________\n",
      "dense_118 (Dense)            multiple                  33        \n",
      "=================================================================\n",
      "Total params: 9,729\n",
      "Trainable params: 9,729\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "for model in models:\n",
    "    model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 258,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8141/8141 [==============================] - 1s 67us/sample - loss: 0.3497 - auc: 0.8901 - accuracy: 0.0000e+00 - precision: 0.8894 - recall: 0.8821\n",
      "8141/8141 [==============================] - 1s 86us/sample - loss: 0.3479 - auc: 0.8872 - accuracy: 0.0000e+00 - precision: 0.8892 - recall: 0.8803\n",
      "8141/8141 [==============================] - 1s 83us/sample - loss: 0.3299 - auc: 0.9052 - accuracy: 0.0000e+00 - precision: 0.8713 - recall: 0.9214\n",
      "8141/8141 [==============================] - 1s 88us/sample - loss: 0.3463 - auc: 0.8894 - accuracy: 0.0000e+00 - precision: 0.8844 - recall: 0.8876\n",
      "8141/8141 [==============================] - 1s 87us/sample - loss: 0.3505 - auc: 0.8882 - accuracy: 0.0000e+00 - precision: 0.8681 - recall: 0.9060\n"
     ]
    }
   ],
   "source": [
    "results = []\n",
    "for model in models:\n",
    "    results.append(model.evaluate(X_test, y_test, batch_size=32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# <TODO> visualize results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 259,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating model 0 on k-fold 0\n",
      "4884/4884 [==============================] - 1s 246us/sample - loss: 0.3785 - auc: 0.8802 - accuracy: 0.0061 - precision: 0.8642 - recall: 0.9073\n",
      "Evaluating model 1 on k-fold 0\n",
      "4884/4884 [==============================] - 1s 218us/sample - loss: 0.3783 - auc: 0.8737 - accuracy: 0.0059 - precision: 0.8617 - recall: 0.8983\n",
      "Evaluating model 2 on k-fold 0\n",
      "4884/4884 [==============================] - 1s 243us/sample - loss: 0.3428 - auc: 0.8911 - accuracy: 4.0950e-04 - precision: 0.8514 - recall: 0.9412\n",
      "Evaluating model 3 on k-fold 0\n",
      "4884/4884 [==============================] - 1s 241us/sample - loss: 0.3658 - auc: 0.8748 - accuracy: 6.1425e-04 - precision: 0.8751 - recall: 0.8829\n",
      "Evaluating model 4 on k-fold 0\n",
      "4884/4884 [==============================] - 1s 214us/sample - loss: 0.3490 - auc: 0.8877 - accuracy: 6.1425e-04 - precision: 0.8650 - recall: 0.9119\n",
      "Evaluating model 0 on k-fold 1\n",
      "4884/4884 [==============================] - 1s 190us/sample - loss: 0.3276 - auc: 0.8999 - accuracy: 0.0027 - precision: 0.8874 - recall: 0.9222\n",
      "Evaluating model 1 on k-fold 1\n",
      "4884/4884 [==============================] - 1s 235us/sample - loss: 0.3580 - auc: 0.8760 - accuracy: 0.0055 - precision: 0.8944 - recall: 0.8715\n",
      "Evaluating model 2 on k-fold 1\n",
      "4884/4884 [==============================] - 1s 238us/sample - loss: 0.3434 - auc: 0.8974 - accuracy: 0.0053 - precision: 0.8856 - recall: 0.8971\n",
      "Evaluating model 3 on k-fold 1\n",
      "4884/4884 [==============================] - 1s 275us/sample - loss: 0.3572 - auc: 0.8770 - accuracy: 0.0041 - precision: 0.8840 - recall: 0.8811\n",
      "Evaluating model 4 on k-fold 1\n",
      "4884/4884 [==============================] - 1s 197us/sample - loss: 0.3334 - auc: 0.9039 - accuracy: 0.0272 - precision: 0.8852 - recall: 0.9264\n",
      "Evaluating model 0 on k-fold 2\n",
      "4884/4884 [==============================] - 1s 263us/sample - loss: 0.3305 - auc: 0.9029 - accuracy: 0.0125 - precision: 0.8576 - recall: 0.9447\n",
      "Evaluating model 1 on k-fold 2\n",
      "4884/4884 [==============================] - 1s 212us/sample - loss: 0.3547 - auc: 0.8838 - accuracy: 0.0180 - precision: 0.8997 - recall: 0.8548\n",
      "Evaluating model 2 on k-fold 2\n",
      "4884/4884 [==============================] - 1s 249us/sample - loss: 0.3444 - auc: 0.8969 - accuracy: 0.0371 - precision: 0.9024 - recall: 0.8611\n",
      "Evaluating model 3 on k-fold 2\n",
      "4884/4884 [==============================] - 1s 245us/sample - loss: 0.3533 - auc: 0.8822 - accuracy: 0.0358 - precision: 0.8809 - recall: 0.8735\n",
      "Evaluating model 4 on k-fold 2\n",
      "4884/4884 [==============================] - 1s 209us/sample - loss: 0.3299 - auc: 0.9072 - accuracy: 0.1114 - precision: 0.8644 - recall: 0.9431\n",
      "Evaluating model 0 on k-fold 3\n",
      "4884/4884 [==============================] - 1s 214us/sample - loss: 0.3173 - auc: 0.9040 - accuracy: 0.0647 - precision: 0.8796 - recall: 0.9357\n",
      "Evaluating model 1 on k-fold 3\n",
      "4884/4884 [==============================] - 1s 215us/sample - loss: 0.3584 - auc: 0.8969 - accuracy: 0.0723 - precision: 0.8681 - recall: 0.9330\n",
      "Evaluating model 2 on k-fold 3\n",
      "4884/4884 [==============================] - 1s 238us/sample - loss: 0.3278 - auc: 0.8981 - accuracy: 0.0850 - precision: 0.8458 - recall: 0.9602\n",
      "Evaluating model 3 on k-fold 3\n",
      "4884/4884 [==============================] - 1s 220us/sample - loss: 0.3579 - auc: 0.8773 - accuracy: 0.0614 - precision: 0.8884 - recall: 0.8733\n",
      "Evaluating model 4 on k-fold 3\n",
      "4884/4884 [==============================] - 1s 278us/sample - loss: 0.3088 - auc: 0.9109 - accuracy: 0.1210 - precision: 0.8806 - recall: 0.9379\n",
      "Evaluating model 0 on k-fold 4\n",
      "4884/4884 [==============================] - 1s 256us/sample - loss: 0.3097 - auc: 0.9122 - accuracy: 0.0760 - precision: 0.8995 - recall: 0.9164\n",
      "Evaluating model 1 on k-fold 4\n",
      "4884/4884 [==============================] - 1s 212us/sample - loss: 0.3380 - auc: 0.8946 - accuracy: 0.0944 - precision: 0.8736 - recall: 0.9344\n",
      "Evaluating model 2 on k-fold 4\n",
      "4884/4884 [==============================] - 1s 241us/sample - loss: 0.3243 - auc: 0.9001 - accuracy: 0.1202 - precision: 0.8754 - recall: 0.9151\n",
      "Evaluating model 3 on k-fold 4\n",
      "4884/4884 [==============================] - 1s 256us/sample - loss: 0.3533 - auc: 0.8791 - accuracy: 0.0940 - precision: 0.8838 - recall: 0.8788\n",
      "Evaluating model 4 on k-fold 4\n",
      "4884/4884 [==============================] - 1s 266us/sample - loss: 0.3138 - auc: 0.9151 - accuracy: 0.1073 - precision: 0.8699 - recall: 0.9610\n"
     ]
    }
   ],
   "source": [
    "# now let's do cross-validation\n",
    "kf = KFold(n_splits=5)\n",
    "for i, (train_idx, test_idx) in enumerate(kf.split(X_train)):\n",
    "    X_trn, X_tst = X_train[train_idx], X_train[test_idx]\n",
    "    y_trn, y_tst = y_train[train_idx], y_train[test_idx]\n",
    "\n",
    "    for j, model in enumerate(models):\n",
    "        model.fit(X_trn, y_trn, batch_size=16, epochs=20, verbose=0)\n",
    "        print(f\"Evaluating model {j} on k-fold {i}\")\n",
    "        model.evaluate(X_tst, y_tst, batch_size=16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 260,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8141/8141 [==============================] - 1s 138us/sample - loss: 0.3132 - auc: 0.9182 - accuracy: 0.0732 - precision: 0.8964 - recall: 0.9201\n",
      "8141/8141 [==============================] - 1s 153us/sample - loss: 0.3326 - auc: 0.9041 - accuracy: 0.0892 - precision: 0.8748 - recall: 0.9369\n",
      "8141/8141 [==============================] - 1s 144us/sample - loss: 0.3299 - auc: 0.9086 - accuracy: 0.1177 - precision: 0.8798 - recall: 0.9242\n",
      "8141/8141 [==============================] - 1s 144us/sample - loss: 0.3582 - auc: 0.8860 - accuracy: 0.0915 - precision: 0.8822 - recall: 0.8892\n",
      "8141/8141 [==============================] - 1s 145us/sample - loss: 0.3311 - auc: 0.9118 - accuracy: 0.1023 - precision: 0.8626 - recall: 0.9632\n"
     ]
    }
   ],
   "source": [
    "# now let's see our performance on the validation set...\n",
    "for model in models:\n",
    "    model.evaluate(X_test, y_test, batch_size=16)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It looks like our final model in particular has a nice recall. This we should probably consider our best candidate recognizing that there is an imbalance in our classes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 264,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_33\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_114 (Dense)            multiple                  1344      \n",
      "_________________________________________________________________\n",
      "dense_115 (Dense)            multiple                  2112      \n",
      "_________________________________________________________________\n",
      "dense_116 (Dense)            multiple                  4160      \n",
      "_________________________________________________________________\n",
      "dense_117 (Dense)            multiple                  2080      \n",
      "_________________________________________________________________\n",
      "dense_118 (Dense)            multiple                  33        \n",
      "_________________________________________________________________\n",
      "dense_119 (Dense)            multiple                  64        \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            multiple                  0         \n",
      "_________________________________________________________________\n",
      "dense_120 (Dense)            multiple                  1056      \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          multiple                  0         \n",
      "_________________________________________________________________\n",
      "dense_121 (Dense)            multiple                  1056      \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          multiple                  0         \n",
      "_________________________________________________________________\n",
      "dense_122 (Dense)            multiple                  33        \n",
      "=================================================================\n",
      "Total params: 11,938\n",
      "Trainable params: 11,938\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "models[-1].summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Regularization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "metadata": {},
   "outputs": [],
   "source": [
    "# now let's do the same procedure but with regularization included; a dropout layer after each\n",
    "regularized_models = []\n",
    "for _ in range(5):\n",
    "    model = tf.keras.models.Sequential()\n",
    "    layers = [ tf.keras.layers.Dense(random.choice(hidden_layers), activation='relu') for _ in range(random.choice(num_layers)) ]\n",
    "    for l in layers:\n",
    "        model.add(l)\n",
    "        dropout_layer = tf.keras.layers.Dropout(.15)\n",
    "        model.add(dropout_layer)\n",
    "    output_layer = tf.keras.layers.Dense(1, activation='sigmoid')\n",
    "    model.add(output_layer)\n",
    "    model.compile(optimizer='adam', loss='binary_crossentropy', metrics = metrics)\n",
    "    regularized_models.append(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating model 0 on k-fold 0\n",
      "4884/4884 [==============================] - 2s 323us/sample - loss: 0.3470 - auc: 0.8904 - accuracy: 0.0000e+00 - precision: 0.8446 - recall: 0.9561\n",
      "Evaluating model 1 on k-fold 0\n",
      "4884/4884 [==============================] - 2s 350us/sample - loss: 0.3465 - auc: 0.8911 - accuracy: 6.1425e-04 - precision: 0.8475 - recall: 0.9534\n",
      "Evaluating model 2 on k-fold 0\n",
      "4884/4884 [==============================] - 2s 341us/sample - loss: 0.3679 - auc: 0.8815 - accuracy: 0.0000e+00 - precision: 0.8372 - recall: 0.9507\n",
      "Evaluating model 3 on k-fold 0\n",
      "4884/4884 [==============================] - 2s 358us/sample - loss: 0.3591 - auc: 0.8811 - accuracy: 0.0000e+00 - precision: 0.8387 - recall: 0.9555\n",
      "Evaluating model 4 on k-fold 0\n",
      "4884/4884 [==============================] - 2s 341us/sample - loss: 0.3750 - auc: 0.8712 - accuracy: 0.0000e+00 - precision: 0.8577 - recall: 0.9035\n",
      "Evaluating model 0 on k-fold 1\n",
      "4884/4884 [==============================] - 1s 266us/sample - loss: 0.3369 - auc: 0.8964 - accuracy: 0.0000e+00 - precision: 0.8602 - recall: 0.9464\n",
      "Evaluating model 1 on k-fold 1\n",
      "4884/4884 [==============================] - 1s 284us/sample - loss: 0.3382 - auc: 0.9009 - accuracy: 2.0475e-04 - precision: 0.8513 - recall: 0.9678\n",
      "Evaluating model 2 on k-fold 1\n",
      "4884/4884 [==============================] - 1s 258us/sample - loss: 0.3527 - auc: 0.8925 - accuracy: 0.0000e+00 - precision: 0.8254 - recall: 0.9843\n",
      "Evaluating model 3 on k-fold 1\n",
      "4884/4884 [==============================] - 1s 270us/sample - loss: 0.3517 - auc: 0.8932 - accuracy: 0.0000e+00 - precision: 0.8308 - recall: 0.9776\n",
      "Evaluating model 4 on k-fold 1\n",
      "4884/4884 [==============================] - 1s 238us/sample - loss: 0.3623 - auc: 0.8739 - accuracy: 0.0182 - precision: 0.8622 - recall: 0.9019\n",
      "Evaluating model 0 on k-fold 2\n",
      "4884/4884 [==============================] - 1s 243us/sample - loss: 0.3329 - auc: 0.9037 - accuracy: 0.0018 - precision: 0.8612 - recall: 0.9461\n",
      "Evaluating model 1 on k-fold 2\n",
      "4884/4884 [==============================] - 1s 257us/sample - loss: 0.3469 - auc: 0.8939 - accuracy: 0.0039 - precision: 0.8408 - recall: 0.9626\n",
      "Evaluating model 2 on k-fold 2\n",
      "4884/4884 [==============================] - 1s 275us/sample - loss: 0.3372 - auc: 0.8982 - accuracy: 0.0000e+00 - precision: 0.8503 - recall: 0.9428\n",
      "Evaluating model 3 on k-fold 2\n",
      "4884/4884 [==============================] - 1s 289us/sample - loss: 0.3468 - auc: 0.8947 - accuracy: 0.0000e+00 - precision: 0.8421 - recall: 0.9621\n",
      "Evaluating model 4 on k-fold 2\n",
      "4884/4884 [==============================] - 2s 332us/sample - loss: 0.3650 - auc: 0.8759 - accuracy: 0.0000e+00 - precision: 0.8627 - recall: 0.8900\n",
      "Evaluating model 0 on k-fold 3\n",
      "4884/4884 [==============================] - 1s 304us/sample - loss: 0.3279 - auc: 0.9035 - accuracy: 0.0018 - precision: 0.8798 - recall: 0.9212\n",
      "Evaluating model 1 on k-fold 3\n",
      "4884/4884 [==============================] - 2s 329us/sample - loss: 0.3277 - auc: 0.8992 - accuracy: 0.0090 - precision: 0.8679 - recall: 0.9328\n",
      "Evaluating model 2 on k-fold 3\n",
      "4884/4884 [==============================] - 1s 292us/sample - loss: 0.3281 - auc: 0.9044 - accuracy: 6.1425e-04 - precision: 0.8387 - recall: 0.9693\n",
      "Evaluating model 3 on k-fold 3\n",
      "4884/4884 [==============================] - 1s 298us/sample - loss: 0.3362 - auc: 0.8972 - accuracy: 0.0000e+00 - precision: 0.8598 - recall: 0.9400\n",
      "Evaluating model 4 on k-fold 3\n",
      "4884/4884 [==============================] - 2s 320us/sample - loss: 0.3630 - auc: 0.8748 - accuracy: 0.0162 - precision: 0.8318 - recall: 0.9190\n",
      "Evaluating model 0 on k-fold 4\n",
      "4884/4884 [==============================] - 2s 314us/sample - loss: 0.3352 - auc: 0.8973 - accuracy: 0.0121 - precision: 0.8486 - recall: 0.9581\n",
      "Evaluating model 1 on k-fold 4\n",
      "4884/4884 [==============================] - 1s 301us/sample - loss: 0.3250 - auc: 0.9026 - accuracy: 0.0164 - precision: 0.8700 - recall: 0.9371\n",
      "Evaluating model 2 on k-fold 4\n",
      "4884/4884 [==============================] - 2s 365us/sample - loss: 0.3466 - auc: 0.8891 - accuracy: 2.0475e-04 - precision: 0.8784 - recall: 0.9087\n",
      "Evaluating model 3 on k-fold 4\n",
      "4884/4884 [==============================] - 2s 340us/sample - loss: 0.3319 - auc: 0.8928 - accuracy: 0.0010 - precision: 0.8596 - recall: 0.9412\n",
      "Evaluating model 4 on k-fold 4\n",
      "4884/4884 [==============================] - 2s 308us/sample - loss: 0.3638 - auc: 0.8730 - accuracy: 0.0352 - precision: 0.8711 - recall: 0.8864\n"
     ]
    }
   ],
   "source": [
    "# now let's do cross-validation\n",
    "kf = KFold(n_splits=5)\n",
    "for i, (train_idx, test_idx) in enumerate(kf.split(X_train)):\n",
    "    X_trn, X_tst = X_train[train_idx], X_train[test_idx]\n",
    "    y_trn, y_tst = y_train[train_idx], y_train[test_idx]\n",
    "\n",
    "    for j, model in enumerate(regularized_models):\n",
    "        model.fit(X_trn, y_trn, batch_size=16, epochs=20, verbose=0)\n",
    "        print(f\"Evaluating model {j} on k-fold {i}\")\n",
    "        model.evaluate(X_tst, y_tst, batch_size=16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 266,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8141/8141 [==============================] - 1s 155us/sample - loss: 0.3342 - auc: 0.9090 - accuracy: 0.0117 - precision: 0.8443 - recall: 0.9649\n",
      "8141/8141 [==============================] - 1s 150us/sample - loss: 0.3242 - auc: 0.9112 - accuracy: 0.0147 - precision: 0.8658 - recall: 0.9418\n",
      "8141/8141 [==============================] - 1s 166us/sample - loss: 0.3409 - auc: 0.8999 - accuracy: 3.6851e-04 - precision: 0.8736 - recall: 0.9165\n",
      "8141/8141 [==============================] - 1s 149us/sample - loss: 0.3257 - auc: 0.9048 - accuracy: 9.8268e-04 - precision: 0.8542 - recall: 0.9462\n",
      "8141/8141 [==============================] - 1s 184us/sample - loss: 0.3507 - auc: 0.8890 - accuracy: 0.0372 - precision: 0.8716 - recall: 0.8980\n"
     ]
    }
   ],
   "source": [
    "# now let's see our performance on the validation set...\n",
    "for model in regularized_models:\n",
    "    model.evaluate(X_test, y_test, batch_size=16)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Feature normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 267,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['age',\n",
       " 'workclass',\n",
       " 'education-num',\n",
       " 'marital-status',\n",
       " 'occupation',\n",
       " 'race',\n",
       " 'sex',\n",
       " 'capital-gain',\n",
       " 'capital-loss',\n",
       " 'hours-per-week',\n",
       " 'native-country',\n",
       " 'target']"
      ]
     },
     "execution_count": 267,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 295,
   "metadata": {},
   "outputs": [],
   "source": [
    "min_max_norm_cols = ['age', 'education-num','hours-per-week']\n",
    "norm_cols = ['capital-gain', 'capital-loss']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 296,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>workclass</th>\n",
       "      <th>education-num</th>\n",
       "      <th>marital-status</th>\n",
       "      <th>occupation</th>\n",
       "      <th>race</th>\n",
       "      <th>sex</th>\n",
       "      <th>capital-gain</th>\n",
       "      <th>capital-loss</th>\n",
       "      <th>hours-per-week</th>\n",
       "      <th>native-country</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.301370</td>\n",
       "      <td>govt</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>Never-married</td>\n",
       "      <td>Adm-clerical</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>0.148451</td>\n",
       "      <td>-0.216656</td>\n",
       "      <td>0.397959</td>\n",
       "      <td>Foreign</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.452055</td>\n",
       "      <td>self</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Exec-managerial</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>-0.145918</td>\n",
       "      <td>-0.216656</td>\n",
       "      <td>0.122449</td>\n",
       "      <td>Foreign</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.287671</td>\n",
       "      <td>private</td>\n",
       "      <td>0.533333</td>\n",
       "      <td>Divorced</td>\n",
       "      <td>Handlers-cleaners</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>-0.145918</td>\n",
       "      <td>-0.216656</td>\n",
       "      <td>0.397959</td>\n",
       "      <td>Foreign</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.493151</td>\n",
       "      <td>private</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Handlers-cleaners</td>\n",
       "      <td>Black</td>\n",
       "      <td>Male</td>\n",
       "      <td>-0.145918</td>\n",
       "      <td>-0.216656</td>\n",
       "      <td>0.397959</td>\n",
       "      <td>Foreign</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.150685</td>\n",
       "      <td>private</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Prof-specialty</td>\n",
       "      <td>Black</td>\n",
       "      <td>Female</td>\n",
       "      <td>-0.145918</td>\n",
       "      <td>-0.216656</td>\n",
       "      <td>0.397959</td>\n",
       "      <td>Foreign</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        age workclass  education-num       marital-status          occupation  \\\n",
       "0  0.301370      govt       0.800000        Never-married        Adm-clerical   \n",
       "1  0.452055      self       0.800000   Married-civ-spouse     Exec-managerial   \n",
       "2  0.287671   private       0.533333             Divorced   Handlers-cleaners   \n",
       "3  0.493151   private       0.400000   Married-civ-spouse   Handlers-cleaners   \n",
       "4  0.150685   private       0.800000   Married-civ-spouse      Prof-specialty   \n",
       "\n",
       "     race      sex  capital-gain  capital-loss  hours-per-week native-country  \\\n",
       "0   White     Male      0.148451     -0.216656        0.397959        Foreign   \n",
       "1   White     Male     -0.145918     -0.216656        0.122449        Foreign   \n",
       "2   White     Male     -0.145918     -0.216656        0.397959        Foreign   \n",
       "3   Black     Male     -0.145918     -0.216656        0.397959        Foreign   \n",
       "4   Black   Female     -0.145918     -0.216656        0.397959        Foreign   \n",
       "\n",
       "   target  \n",
       "0   <=50K  \n",
       "1   <=50K  \n",
       "2   <=50K  \n",
       "3   <=50K  \n",
       "4   <=50K  "
      ]
     },
     "execution_count": 296,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# age & education we'll use MinMax, the others we'll do normalization\n",
    "for col in min_max_norm_cols:\n",
    "    df[col] = (df[col] - df[col].min()) / (df[col].max() - df[col].min())\n",
    "\n",
    "for col in norm_cols:\n",
    "    df[col] = (df[col] - df[col].mean()) / df[col].std()\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 297,
   "metadata": {},
   "outputs": [],
   "source": [
    "target = df.target\n",
    "X_normed = pd.get_dummies(df.drop(['target'], axis=1)).values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 298,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_norm_train, X_norm_test, y_norm_train, y_norm_test = train_test_split(X_normed, y, test_size=.25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 300,
   "metadata": {},
   "outputs": [],
   "source": [
    "normed_models = []\n",
    "for _ in range(5):\n",
    "    m = tf.keras.models.Sequential()\n",
    "    layers = [ tf.keras.layers.Dense(random.choice(hidden_layers), activation='relu') for _ in range(random.choice(num_layers)) ]\n",
    "    for l in layers:\n",
    "        m.add(l)\n",
    "        dropout_layer = tf.keras.layers.Dropout(.15)\n",
    "        m.add(dropout_layer)\n",
    "    output_layer = tf.keras.layers.Dense(1, activation='sigmoid')\n",
    "    m.add(output_layer)\n",
    "    m.compile(optimizer='adam', loss='binary_crossentropy', metrics = metrics)\n",
    "    normed_models.append(m)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 301,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating model 0 on k-fold 0\n",
      "4884/4884 [==============================] - 2s 354us/sample - loss: 0.3098 - auc: 0.9124 - accuracy: 0.0051 - precision: 0.8775 - recall: 0.9442\n",
      "Evaluating model 1 on k-fold 0\n",
      "4884/4884 [==============================] - 2s 373us/sample - loss: 0.3104 - auc: 0.9127 - accuracy: 0.0014 - precision: 0.8679 - recall: 0.9488\n",
      "Evaluating model 2 on k-fold 0\n",
      "4884/4884 [==============================] - 2s 312us/sample - loss: 0.3165 - auc: 0.9108 - accuracy: 0.0027 - precision: 0.8705 - recall: 0.9472\n",
      "Evaluating model 3 on k-fold 0\n",
      "4884/4884 [==============================] - 2s 486us/sample - loss: 0.3122 - auc: 0.9121 - accuracy: 0.0027 - precision: 0.8653 - recall: 0.9542\n",
      "Evaluating model 4 on k-fold 0\n",
      "4884/4884 [==============================] - 3s 585us/sample - loss: 0.3112 - auc: 0.9124 - accuracy: 0.0031 - precision: 0.8711 - recall: 0.9485\n",
      "Evaluating model 0 on k-fold 1\n",
      "4884/4884 [==============================] - 1s 301us/sample - loss: 0.3033 - auc: 0.9133 - accuracy: 0.0147 - precision: 0.8869 - recall: 0.9374\n",
      "Evaluating model 1 on k-fold 1\n",
      "4884/4884 [==============================] - 3s 534us/sample - loss: 0.3011 - auc: 0.9147 - accuracy: 0.0047 - precision: 0.8861 - recall: 0.9342\n",
      "Evaluating model 2 on k-fold 1\n",
      "4884/4884 [==============================] - 2s 383us/sample - loss: 0.2983 - auc: 0.9155 - accuracy: 0.0047 - precision: 0.8863 - recall: 0.9425\n",
      "Evaluating model 3 on k-fold 1\n",
      "4884/4884 [==============================] - 2s 510us/sample - loss: 0.2988 - auc: 0.9153 - accuracy: 0.0113 - precision: 0.8809 - recall: 0.9478\n",
      "Evaluating model 4 on k-fold 1\n",
      "4884/4884 [==============================] - 2s 352us/sample - loss: 0.3050 - auc: 0.9128 - accuracy: 0.0205 - precision: 0.8992 - recall: 0.9184\n",
      "Evaluating model 0 on k-fold 2\n",
      "4884/4884 [==============================] - 1s 292us/sample - loss: 0.3137 - auc: 0.9117 - accuracy: 0.0307 - precision: 0.8726 - recall: 0.9356\n",
      "Evaluating model 1 on k-fold 2\n",
      "4884/4884 [==============================] - 1s 293us/sample - loss: 0.3069 - auc: 0.9152 - accuracy: 0.0215 - precision: 0.8801 - recall: 0.9294\n",
      "Evaluating model 2 on k-fold 2\n",
      "4884/4884 [==============================] - 1s 211us/sample - loss: 0.3067 - auc: 0.9145 - accuracy: 0.0066 - precision: 0.8648 - recall: 0.9465\n",
      "Evaluating model 3 on k-fold 2\n",
      "4884/4884 [==============================] - 1s 292us/sample - loss: 0.3119 - auc: 0.9135 - accuracy: 0.0192 - precision: 0.8760 - recall: 0.9348\n",
      "Evaluating model 4 on k-fold 2\n",
      "4884/4884 [==============================] - 2s 319us/sample - loss: 0.3091 - auc: 0.9122 - accuracy: 0.0438 - precision: 0.8791 - recall: 0.9280\n",
      "Evaluating model 0 on k-fold 3\n",
      "4884/4884 [==============================] - 1s 279us/sample - loss: 0.3174 - auc: 0.9097 - accuracy: 0.0254 - precision: 0.8968 - recall: 0.9147\n",
      "Evaluating model 1 on k-fold 3\n",
      "4884/4884 [==============================] - 1s 265us/sample - loss: 0.3082 - auc: 0.9123 - accuracy: 0.0287 - precision: 0.9019 - recall: 0.9050\n",
      "Evaluating model 2 on k-fold 3\n",
      "4884/4884 [==============================] - 1s 287us/sample - loss: 0.3119 - auc: 0.9091 - accuracy: 0.0059 - precision: 0.8784 - recall: 0.9396\n",
      "Evaluating model 3 on k-fold 3\n",
      "4884/4884 [==============================] - 1s 287us/sample - loss: 0.3149 - auc: 0.9112 - accuracy: 0.0303 - precision: 0.8934 - recall: 0.9161\n",
      "Evaluating model 4 on k-fold 3\n",
      "4884/4884 [==============================] - 2s 369us/sample - loss: 0.3103 - auc: 0.9102 - accuracy: 0.0647 - precision: 0.8904 - recall: 0.9269\n",
      "Evaluating model 0 on k-fold 4\n",
      "4884/4884 [==============================] - 1s 293us/sample - loss: 0.2938 - auc: 0.9231 - accuracy: 0.0305 - precision: 0.8904 - recall: 0.9382\n",
      "Evaluating model 1 on k-fold 4\n",
      "4884/4884 [==============================] - 2s 312us/sample - loss: 0.2958 - auc: 0.9228 - accuracy: 0.0526 - precision: 0.8988 - recall: 0.9325\n",
      "Evaluating model 2 on k-fold 4\n",
      "4884/4884 [==============================] - 2s 313us/sample - loss: 0.2887 - auc: 0.9236 - accuracy: 0.0100 - precision: 0.8860 - recall: 0.9501\n",
      "Evaluating model 3 on k-fold 4\n",
      "4884/4884 [==============================] - 1s 297us/sample - loss: 0.2852 - auc: 0.9259 - accuracy: 0.0330 - precision: 0.9050 - recall: 0.9282\n",
      "Evaluating model 4 on k-fold 4\n",
      "4884/4884 [==============================] - 2s 318us/sample - loss: 0.2867 - auc: 0.9267 - accuracy: 0.0954 - precision: 0.8929 - recall: 0.9428\n"
     ]
    }
   ],
   "source": [
    "# now let's do cross-validation\n",
    "kf = KFold(n_splits=5)\n",
    "for i, (train_idx, test_idx) in enumerate(kf.split(X_norm_train)):\n",
    "    X_trn, X_tst = X_norm_train[train_idx], X_norm_train[test_idx]\n",
    "    y_trn, y_tst = y_norm_train[train_idx], y_norm_train[test_idx]\n",
    "\n",
    "    for j, model in enumerate(normed_models):\n",
    "        model.fit(X_trn, y_trn, batch_size=16, epochs=20, verbose=0)\n",
    "        print(f\"Evaluating model {j} on k-fold {i}\")\n",
    "        model.evaluate(X_tst, y_tst, batch_size=16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 302,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8141/8141 [==============================] - 1s 175us/sample - loss: 0.3276 - auc: 0.9068 - accuracy: 0.0335 - precision: 0.8830 - recall: 0.9370\n",
      "8141/8141 [==============================] - 1s 180us/sample - loss: 0.3298 - auc: 0.9074 - accuracy: 0.0555 - precision: 0.8891 - recall: 0.9310\n",
      "8141/8141 [==============================] - 1s 136us/sample - loss: 0.3086 - auc: 0.9124 - accuracy: 0.0090 - precision: 0.8784 - recall: 0.9505\n",
      "8141/8141 [==============================] - 1s 152us/sample - loss: 0.3280 - auc: 0.9094 - accuracy: 0.0341 - precision: 0.8944 - recall: 0.9259\n",
      "8141/8141 [==============================] - 1s 137us/sample - loss: 0.3351 - auc: 0.9081 - accuracy: 0.0882 - precision: 0.8852 - recall: 0.9377\n"
     ]
    }
   ],
   "source": [
    "# now let's see our performance on the validation set...\n",
    "for m in normed_models:\n",
    "    m.evaluate(X_norm_test, y_norm_test, batch_size=16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:deep-learning-spring-20] *",
   "language": "python",
   "name": "conda-env-deep-learning-spring-20-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
