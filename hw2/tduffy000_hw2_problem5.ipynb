{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Homework 2, Problem 5\n",
    "\n",
    "In this problem we look at weather and how it impacts trading on the New York stock enchange. Complete this notebook and keep it in a homework 2 repo. Submit the repo link though the blackboard.\n",
    "\n",
    "**You are free to add implmentation or markdown cells to make your notebook clearer!!**\n",
    "\n",
    "## Data:\n",
    "\n",
    "The following two datasets are our focus\n",
    "\n",
    "* Weather data [NOAA-GHCN](https://registry.opendata.aws/noaa-ghcn/)\n",
    "* Stock Exchange Data [Yahoo Finance](https://finance.yahoo.com/quote/%5ENYA/history?ltr=1) \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 1: Download The Weather Data\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "source": [
    "Download a year of weather data.\n",
    "\n",
    "The Raw GHCN files don't have column headers, so we manually add them in. It's safer to at this point read in everything as an object & then parse to the correct type once you extract the variables you're interested in. \n",
    "This information can be found in https://docs.opendata.aws/noaa-ghcn-pds/readme.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [],
   "source": [
    "import urllib \n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "import dask.dataframe as dd\n",
    "import dask.bag as db\n",
    "import dask.diagnostics as dg"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We're using Dask for the lazy evaluation properties (it will only try to run the computations at the end, hopefully after the data has been filtered down) because the dataset is very large. We set the storage options to `anon=True` because this data is public. Otherwise this kwarg is where we'd pass in the AWS authorization keys. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [],
   "source": [
    "# Let's load in the data for 1992\n",
    "YEAR = 1992\n",
    "\n",
    "names = ['ID', 'DATE', 'ELEMENT', 'DATA_VALUE', 'M-FLAG', 'Q-FLAG', 'S-FLAG', 'OBS-TIME']\n",
    "ds = dd.read_csv(f's3://noaa-ghcn-pds/csv/{YEAR}.csv', storage_options={'anon':True},  names=names, memory_map=False, \n",
    "                  dtype={'DATA_VALUE':'object'}, parse_dates=['DATE', 'OBS-TIME'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['ID', 'DATE', 'ELEMENT', 'DATA_VALUE', 'M-FLAG', 'Q-FLAG', 'S-FLAG',\n",
      "       'OBS-TIME'],\n",
      "      dtype='object')\n",
      "ID                    object\n",
      "DATE          datetime64[ns]\n",
      "ELEMENT               object\n",
      "DATA_VALUE            object\n",
      "M-FLAG                object\n",
      "Q-FLAG                object\n",
      "S-FLAG                object\n",
      "OBS-TIME              object\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "# You can check the data\n",
    "print(ds.columns)\n",
    "print(ds.dtypes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>DATE</th>\n",
       "      <th>ELEMENT</th>\n",
       "      <th>DATA_VALUE</th>\n",
       "      <th>M-FLAG</th>\n",
       "      <th>Q-FLAG</th>\n",
       "      <th>S-FLAG</th>\n",
       "      <th>OBS-TIME</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>CA002303986</td>\n",
       "      <td>1992-01-01</td>\n",
       "      <td>TMAX</td>\n",
       "      <td>-70</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>C</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>CA002303986</td>\n",
       "      <td>1992-01-01</td>\n",
       "      <td>TMIN</td>\n",
       "      <td>-240</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>C</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>CA002303986</td>\n",
       "      <td>1992-01-01</td>\n",
       "      <td>PRCP</td>\n",
       "      <td>4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>C</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>CA002303986</td>\n",
       "      <td>1992-01-01</td>\n",
       "      <td>SNOW</td>\n",
       "      <td>4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>C</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>CA002303986</td>\n",
       "      <td>1992-01-01</td>\n",
       "      <td>SNWD</td>\n",
       "      <td>420</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>C</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            ID       DATE ELEMENT DATA_VALUE M-FLAG Q-FLAG S-FLAG OBS-TIME\n",
       "0  CA002303986 1992-01-01    TMAX        -70    NaN    NaN      C      NaN\n",
       "1  CA002303986 1992-01-01    TMIN       -240    NaN    NaN      C      NaN\n",
       "2  CA002303986 1992-01-01    PRCP          4    NaN    NaN      C      NaN\n",
       "3  CA002303986 1992-01-01    SNOW          4    NaN    NaN      C      NaN\n",
       "4  CA002303986 1992-01-01    SNWD        420    NaN    NaN      C      NaN"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Print out the first few rows\n",
    "ds.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we want to parse out the station ID list. We are using [pandas.read_fwf](https://pandas.pydata.org/pandas-docs/version/0.23.4/generated/pandas.read_fwf.html#pandas.read_fwf) because this file is a fixed format width table rather than a csv file. \n",
    "We explicitly pass in the extents of the fixed width field because Pandas has trouble inferring what belongs in the `STATE` column versus in the `NAME` column. We obtained these extents from the readme https://docs.opendata.aws/noaa-ghcn-pds/readme.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# {column name:extents of the fixed-width fields}\n",
    "columns = {\"ID\": (0,11), \"LATITUDE\": (12, 20), \"LONGITUDE\": (21, 30), \"ELEVATION\": (31, 37),\"STATE\": (38, 40),\n",
    "           \"NAME\": (41, 71), \"GSN FLAG\": (72, 75), \"HCN/CRN FLAG\": (76, 79),\"WMO ID\": (80, 85)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_fwf(\"http://noaa-ghcn-pds.s3.amazonaws.com/ghcnd-stations.txt\", \n",
    "                    colspecs=list(columns.values()), names=list(columns.keys()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>LATITUDE</th>\n",
       "      <th>LONGITUDE</th>\n",
       "      <th>ELEVATION</th>\n",
       "      <th>STATE</th>\n",
       "      <th>NAME</th>\n",
       "      <th>GSN FLAG</th>\n",
       "      <th>HCN/CRN FLAG</th>\n",
       "      <th>WMO ID</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ACW00011604</td>\n",
       "      <td>17.1167</td>\n",
       "      <td>-61.7833</td>\n",
       "      <td>10.1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>ST JOHNS COOLIDGE FLD</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ACW00011647</td>\n",
       "      <td>17.1333</td>\n",
       "      <td>-61.7833</td>\n",
       "      <td>19.2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>ST JOHNS</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>AE000041196</td>\n",
       "      <td>25.3330</td>\n",
       "      <td>55.5170</td>\n",
       "      <td>34.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>SHARJAH INTER. AIRP</td>\n",
       "      <td>GSN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>41196.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>AEM00041194</td>\n",
       "      <td>25.2550</td>\n",
       "      <td>55.3640</td>\n",
       "      <td>10.4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>DUBAI INTL</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>41194.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>AEM00041217</td>\n",
       "      <td>24.4330</td>\n",
       "      <td>54.6510</td>\n",
       "      <td>26.8</td>\n",
       "      <td>NaN</td>\n",
       "      <td>ABU DHABI INTL</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>41217.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            ID  LATITUDE  LONGITUDE  ELEVATION STATE                   NAME  \\\n",
       "0  ACW00011604   17.1167   -61.7833       10.1   NaN  ST JOHNS COOLIDGE FLD   \n",
       "1  ACW00011647   17.1333   -61.7833       19.2   NaN               ST JOHNS   \n",
       "2  AE000041196   25.3330    55.5170       34.0   NaN    SHARJAH INTER. AIRP   \n",
       "3  AEM00041194   25.2550    55.3640       10.4   NaN             DUBAI INTL   \n",
       "4  AEM00041217   24.4330    54.6510       26.8   NaN         ABU DHABI INTL   \n",
       "\n",
       "  GSN FLAG HCN/CRN FLAG   WMO ID  \n",
       "0      NaN          NaN      NaN  \n",
       "1      NaN          NaN      NaN  \n",
       "2      GSN          NaN  41196.0  \n",
       "3      NaN          NaN  41194.0  \n",
       "4      NaN          NaN  41217.0  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>LATITUDE</th>\n",
       "      <th>LONGITUDE</th>\n",
       "      <th>ELEVATION</th>\n",
       "      <th>STATE</th>\n",
       "      <th>NAME</th>\n",
       "      <th>GSN FLAG</th>\n",
       "      <th>HCN/CRN FLAG</th>\n",
       "      <th>WMO ID</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>73674</th>\n",
       "      <td>US1NJAT0001</td>\n",
       "      <td>39.5483</td>\n",
       "      <td>-74.8671</td>\n",
       "      <td>31.4</td>\n",
       "      <td>NJ</td>\n",
       "      <td>BUENA VISTA TWP 2.6 NNE</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>73675</th>\n",
       "      <td>US1NJAT0002</td>\n",
       "      <td>39.5565</td>\n",
       "      <td>-74.8048</td>\n",
       "      <td>14.0</td>\n",
       "      <td>NJ</td>\n",
       "      <td>FOLSOM 3.2 SE</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>73676</th>\n",
       "      <td>US1NJAT0003</td>\n",
       "      <td>39.4747</td>\n",
       "      <td>-74.7107</td>\n",
       "      <td>5.5</td>\n",
       "      <td>NJ</td>\n",
       "      <td>HAMILTON TWP 2.1 SE</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>73677</th>\n",
       "      <td>US1NJAT0005</td>\n",
       "      <td>39.6404</td>\n",
       "      <td>-74.8261</td>\n",
       "      <td>29.9</td>\n",
       "      <td>NJ</td>\n",
       "      <td>HAMMONTON 3.3 WSW</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>73678</th>\n",
       "      <td>US1NJAT0009</td>\n",
       "      <td>39.3346</td>\n",
       "      <td>-74.5759</td>\n",
       "      <td>5.8</td>\n",
       "      <td>NJ</td>\n",
       "      <td>LINWOOD 0.7 SSW</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                ID  LATITUDE  LONGITUDE  ELEVATION STATE  \\\n",
       "73674  US1NJAT0001   39.5483   -74.8671       31.4    NJ   \n",
       "73675  US1NJAT0002   39.5565   -74.8048       14.0    NJ   \n",
       "73676  US1NJAT0003   39.4747   -74.7107        5.5    NJ   \n",
       "73677  US1NJAT0005   39.6404   -74.8261       29.9    NJ   \n",
       "73678  US1NJAT0009   39.3346   -74.5759        5.8    NJ   \n",
       "\n",
       "                          NAME GSN FLAG HCN/CRN FLAG  WMO ID  \n",
       "73674  BUENA VISTA TWP 2.6 NNE      NaN          NaN     NaN  \n",
       "73675            FOLSOM 3.2 SE      NaN          NaN     NaN  \n",
       "73676      HAMILTON TWP 2.1 SE      NaN          NaN     NaN  \n",
       "73677        HAMMONTON 3.3 WSW      NaN          NaN     NaN  \n",
       "73678          LINWOOD 0.7 SSW      NaN          NaN     NaN  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# You should be looking for those in the New York area like Central Park, JFK, LGA and Newark airport.\n",
    "NYNJ = df[df['STATE'].isin(['NY', 'NJ'])]\n",
    "NYNJ.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Central Park is coded in shorthand, so we used the NOAA web portal to look up the correct ID\n",
    "https://www.ncdc.noaa.gov/cdo-web/datasets/GHCND/stations/GHCND:USW00094728/detail"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>LATITUDE</th>\n",
       "      <th>LONGITUDE</th>\n",
       "      <th>ELEVATION</th>\n",
       "      <th>STATE</th>\n",
       "      <th>NAME</th>\n",
       "      <th>GSN FLAG</th>\n",
       "      <th>HCN/CRN FLAG</th>\n",
       "      <th>WMO ID</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>114226</th>\n",
       "      <td>USW00094728</td>\n",
       "      <td>40.7789</td>\n",
       "      <td>-73.9692</td>\n",
       "      <td>39.6</td>\n",
       "      <td>NY</td>\n",
       "      <td>NEW YORK CNTRL PK TWR</td>\n",
       "      <td>NaN</td>\n",
       "      <td>HCN</td>\n",
       "      <td>72506.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 ID  LATITUDE  LONGITUDE  ELEVATION STATE  \\\n",
       "114226  USW00094728   40.7789   -73.9692       39.6    NY   \n",
       "\n",
       "                         NAME GSN FLAG HCN/CRN FLAG   WMO ID  \n",
       "114226  NEW YORK CNTRL PK TWR      NaN          HCN  72506.0  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "NYNJ[NYNJ['ID'].str.contains('USW00094728')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>LATITUDE</th>\n",
       "      <th>LONGITUDE</th>\n",
       "      <th>ELEVATION</th>\n",
       "      <th>STATE</th>\n",
       "      <th>NAME</th>\n",
       "      <th>GSN FLAG</th>\n",
       "      <th>HCN/CRN FLAG</th>\n",
       "      <th>WMO ID</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>100219</th>\n",
       "      <td>USC00305840</td>\n",
       "      <td>43.1139</td>\n",
       "      <td>-78.9353</td>\n",
       "      <td>179.2</td>\n",
       "      <td>NY</td>\n",
       "      <td>NIAGARA FALLS INTL AP</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>112764</th>\n",
       "      <td>USW00004724</td>\n",
       "      <td>43.1072</td>\n",
       "      <td>-78.9453</td>\n",
       "      <td>178.3</td>\n",
       "      <td>NY</td>\n",
       "      <td>NIAGARA FALLS INTL AP</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>112769</th>\n",
       "      <td>USW00004742</td>\n",
       "      <td>44.6500</td>\n",
       "      <td>-73.4667</td>\n",
       "      <td>71.9</td>\n",
       "      <td>NY</td>\n",
       "      <td>PLATTSBURGH INTL AP</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>112775</th>\n",
       "      <td>USW00004781</td>\n",
       "      <td>40.7939</td>\n",
       "      <td>-73.1017</td>\n",
       "      <td>25.6</td>\n",
       "      <td>NY</td>\n",
       "      <td>ISLIP LI MACARTHUR AP</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>72505.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>112779</th>\n",
       "      <td>USW00004789</td>\n",
       "      <td>41.5092</td>\n",
       "      <td>-74.2650</td>\n",
       "      <td>111.3</td>\n",
       "      <td>NY</td>\n",
       "      <td>MONTGOMERY ORANGE AP</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 ID  LATITUDE  LONGITUDE  ELEVATION STATE  \\\n",
       "100219  USC00305840   43.1139   -78.9353      179.2    NY   \n",
       "112764  USW00004724   43.1072   -78.9453      178.3    NY   \n",
       "112769  USW00004742   44.6500   -73.4667       71.9    NY   \n",
       "112775  USW00004781   40.7939   -73.1017       25.6    NY   \n",
       "112779  USW00004789   41.5092   -74.2650      111.3    NY   \n",
       "\n",
       "                         NAME GSN FLAG HCN/CRN FLAG   WMO ID  \n",
       "100219  NIAGARA FALLS INTL AP      NaN          NaN      NaN  \n",
       "112764  NIAGARA FALLS INTL AP      NaN          NaN      NaN  \n",
       "112769    PLATTSBURGH INTL AP      NaN          NaN      NaN  \n",
       "112775  ISLIP LI MACARTHUR AP      NaN          NaN  72505.0  \n",
       "112779   MONTGOMERY ORANGE AP      NaN          NaN      NaN  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Airports + Central Park\n",
    "apcp = NYNJ[NYNJ['NAME'].str.endswith('AP') | NYNJ['ID'].str.contains('USW00094728')]\n",
    "apcp.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What we're interested in is the IDs, which we will use for our dataset to obtain only the stations of interest. We are going to join our two dataframes on the ID column so that we have all the information in every row.  We are removing the flags since they have neither computational nor necessary identification information. \n",
    "\n",
    "we do not use `.compute()` to resolve the computation because it's better to hold off until the completetion of feature selection and engineering described below. If you'd like a fully computed dataframe, the code is \n",
    "```python\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "nyds = ds.merge(apcp[['ID', 'LATITUDE', 'LONGITUDE', 'ELEVATION', 'STATE', 'NAME']], on='ID')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>DATE</th>\n",
       "      <th>ELEMENT</th>\n",
       "      <th>DATA_VALUE</th>\n",
       "      <th>M-FLAG</th>\n",
       "      <th>Q-FLAG</th>\n",
       "      <th>S-FLAG</th>\n",
       "      <th>OBS-TIME</th>\n",
       "      <th>LATITUDE</th>\n",
       "      <th>LONGITUDE</th>\n",
       "      <th>ELEVATION</th>\n",
       "      <th>STATE</th>\n",
       "      <th>NAME</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>USW00094790</td>\n",
       "      <td>1992-01-01</td>\n",
       "      <td>TMAX</td>\n",
       "      <td>61</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>2400</td>\n",
       "      <td>43.9922</td>\n",
       "      <td>-76.0217</td>\n",
       "      <td>96.9</td>\n",
       "      <td>NY</td>\n",
       "      <td>WATERTOWN INTL AP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>USW00094790</td>\n",
       "      <td>1992-01-01</td>\n",
       "      <td>TMIN</td>\n",
       "      <td>-133</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>2400</td>\n",
       "      <td>43.9922</td>\n",
       "      <td>-76.0217</td>\n",
       "      <td>96.9</td>\n",
       "      <td>NY</td>\n",
       "      <td>WATERTOWN INTL AP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>USW00094790</td>\n",
       "      <td>1992-01-01</td>\n",
       "      <td>PRCP</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>2400</td>\n",
       "      <td>43.9922</td>\n",
       "      <td>-76.0217</td>\n",
       "      <td>96.9</td>\n",
       "      <td>NY</td>\n",
       "      <td>WATERTOWN INTL AP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>USW00094790</td>\n",
       "      <td>1992-01-01</td>\n",
       "      <td>SNOW</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>43.9922</td>\n",
       "      <td>-76.0217</td>\n",
       "      <td>96.9</td>\n",
       "      <td>NY</td>\n",
       "      <td>WATERTOWN INTL AP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>USW00094790</td>\n",
       "      <td>1992-01-01</td>\n",
       "      <td>SNWD</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>43.9922</td>\n",
       "      <td>-76.0217</td>\n",
       "      <td>96.9</td>\n",
       "      <td>NY</td>\n",
       "      <td>WATERTOWN INTL AP</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            ID       DATE ELEMENT DATA_VALUE M-FLAG Q-FLAG S-FLAG OBS-TIME  \\\n",
       "0  USW00094790 1992-01-01    TMAX         61    NaN    NaN      0     2400   \n",
       "1  USW00094790 1992-01-01    TMIN       -133    NaN    NaN      0     2400   \n",
       "2  USW00094790 1992-01-01    PRCP          0    NaN    NaN      0     2400   \n",
       "3  USW00094790 1992-01-01    SNOW          0    NaN    NaN      0      NaN   \n",
       "4  USW00094790 1992-01-01    SNWD          0    NaN    NaN      0      NaN   \n",
       "\n",
       "   LATITUDE  LONGITUDE  ELEVATION STATE               NAME  \n",
       "0   43.9922   -76.0217       96.9    NY  WATERTOWN INTL AP  \n",
       "1   43.9922   -76.0217       96.9    NY  WATERTOWN INTL AP  \n",
       "2   43.9922   -76.0217       96.9    NY  WATERTOWN INTL AP  \n",
       "3   43.9922   -76.0217       96.9    NY  WATERTOWN INTL AP  \n",
       "4   43.9922   -76.0217       96.9    NY  WATERTOWN INTL AP  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nyds.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "source": [
    "## Part 2: Download Stock Price Data\n",
    "\n",
    "Here the idea is to get the finance data from Yahoo finace.  It's already the right date range in general:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [],
   "source": [
    "finance_df = pd.read_csv(\"https://query1.finance.yahoo.com/v7/finance/download/%5ENYA?period1=694224000&period2=725760000&interval=1d&events=history\")\n",
    "finance_df = finance_df.rename(columns={\"Date\": \"DATE\"})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can do an inner join for the dates from the financial dataset and the new york weather dataset, to get all your features ready, please do that here:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# your join on dates goes here:\n",
    "ny_df = nyds.compute()\n",
    "ny_df[\"DATE\"] = pd.to_datetime(ny_df[\"DATE\"])\n",
    "finance_df[\"DATE\"] = pd.to_datetime(finance_df[\"DATE\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ID                    object\n",
       "DATE          datetime64[ns]\n",
       "ELEMENT               object\n",
       "DATA_VALUE            object\n",
       "M-FLAG                object\n",
       "Q-FLAG                object\n",
       "S-FLAG                object\n",
       "OBS-TIME              object\n",
       "LATITUDE             float64\n",
       "LONGITUDE            float64\n",
       "ELEVATION            float64\n",
       "STATE                 object\n",
       "NAME                  object\n",
       "dtype: object"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ny_df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "ny_df = ny_df.astype({'DATA_VALUE': 'float'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "pivoted_ny = pd.pivot_table(ny_df, values='DATA_VALUE', columns=['ELEMENT'], index=['ID', 'DATE'], aggfunc=np.max, fill_value=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "# inner join on ny_df.DATE == finance_df.DATE \n",
    "joined_data = pd.merge(finance_df, pivoted_ny, on = 'DATE', how = 'inner')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "source": [
    "## Part 3: Creating and Selecting Variables\n",
    "\n",
    "Pull out and encode the various variables listed below and set up these varaibles at least initially in a pandas data frame.\n",
    "\n",
    "### Weather variables\n",
    "\n",
    "* raining:\n",
    "    - 0 - wasn't raining\n",
    "    - 1 - was raining\n",
    "* rain intensity:\n",
    "    - 0 -low\n",
    "    - 1 - medium\n",
    "    - 2 - high\n",
    "* rain duration in hours\n",
    "* snowing:\n",
    "    - 0 - wasn't snowing\n",
    "    - 1 - was snowing\n",
    "* snow intensity:\n",
    "    - 0 - low\n",
    "    - 1 - medium\n",
    "    - 2 - high\n",
    "* snow duration in hours\n",
    "* windy:\n",
    "    - 0 - low\n",
    "    - 1 - medium\n",
    "    - 2 - high"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "# rain indicator\n",
    "joined_data['was_raining'] = ((joined_data.SNOW == 0) & (joined_data.PRCP > 0)).astype(\"int\")\n",
    "\n",
    "# rain intensity (minmax norm)\n",
    "joined_data['prcp_intensity'] = (joined_data.PRCP - joined_data.PRCP.min()) / (joined_data.PRCP.max() - joined_data.PRCP.min()) \n",
    "\n",
    "# snowing variable\n",
    "joined_data['was_snowing'] = (joined_data.SNOW > 0).astype(\"int\")\n",
    "\n",
    "# snow intensity (minmax norm)\n",
    "joined_data['snow_intensity'] = (joined_data.SNOW - joined_data.SNOW.min()) / (joined_data.SNOW.max() - joined_data.SNOW.min())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>DATE</th>\n",
       "      <th>Open</th>\n",
       "      <th>High</th>\n",
       "      <th>Low</th>\n",
       "      <th>Close</th>\n",
       "      <th>Adj Close</th>\n",
       "      <th>Volume</th>\n",
       "      <th>ACMH</th>\n",
       "      <th>ACSH</th>\n",
       "      <th>AWND</th>\n",
       "      <th>...</th>\n",
       "      <th>WT14</th>\n",
       "      <th>WT15</th>\n",
       "      <th>WT16</th>\n",
       "      <th>WT17</th>\n",
       "      <th>WT18</th>\n",
       "      <th>WT22</th>\n",
       "      <th>was_raining</th>\n",
       "      <th>prcp_intensity</th>\n",
       "      <th>was_snowing</th>\n",
       "      <th>snow_intensity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1992-01-02</td>\n",
       "      <td>2423.179932</td>\n",
       "      <td>2423.179932</td>\n",
       "      <td>2423.179932</td>\n",
       "      <td>2423.179932</td>\n",
       "      <td>2423.179932</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1992-01-02</td>\n",
       "      <td>2423.179932</td>\n",
       "      <td>2423.179932</td>\n",
       "      <td>2423.179932</td>\n",
       "      <td>2423.179932</td>\n",
       "      <td>2423.179932</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>20</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1992-01-02</td>\n",
       "      <td>2423.179932</td>\n",
       "      <td>2423.179932</td>\n",
       "      <td>2423.179932</td>\n",
       "      <td>2423.179932</td>\n",
       "      <td>2423.179932</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1992-01-02</td>\n",
       "      <td>2423.179932</td>\n",
       "      <td>2423.179932</td>\n",
       "      <td>2423.179932</td>\n",
       "      <td>2423.179932</td>\n",
       "      <td>2423.179932</td>\n",
       "      <td>0</td>\n",
       "      <td>100</td>\n",
       "      <td>90</td>\n",
       "      <td>34</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1992-01-02</td>\n",
       "      <td>2423.179932</td>\n",
       "      <td>2423.179932</td>\n",
       "      <td>2423.179932</td>\n",
       "      <td>2423.179932</td>\n",
       "      <td>2423.179932</td>\n",
       "      <td>0</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>18</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 43 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        DATE         Open         High          Low        Close    Adj Close  \\\n",
       "0 1992-01-02  2423.179932  2423.179932  2423.179932  2423.179932  2423.179932   \n",
       "1 1992-01-02  2423.179932  2423.179932  2423.179932  2423.179932  2423.179932   \n",
       "2 1992-01-02  2423.179932  2423.179932  2423.179932  2423.179932  2423.179932   \n",
       "3 1992-01-02  2423.179932  2423.179932  2423.179932  2423.179932  2423.179932   \n",
       "4 1992-01-02  2423.179932  2423.179932  2423.179932  2423.179932  2423.179932   \n",
       "\n",
       "   Volume  ACMH  ACSH  AWND  ...  WT14  WT15  WT16  WT17  WT18  WT22  \\\n",
       "0       0     0     0     0  ...     0     0     0     0     0     0   \n",
       "1       0     0     0    20  ...     0     0     0     0     0     0   \n",
       "2       0     0     0     0  ...     1     0     1     0     0     0   \n",
       "3       0   100    90    34  ...     0     0     0     0     0     0   \n",
       "4       0   100   100    18  ...     0     0     1     0     0     0   \n",
       "\n",
       "   was_raining  prcp_intensity  was_snowing  snow_intensity  \n",
       "0            0             0.0            0             0.0  \n",
       "1            0             0.0            0             0.0  \n",
       "2            0             0.0            0             0.0  \n",
       "3            0             0.0            0             0.0  \n",
       "4            0             0.0            0             0.0  \n",
       "\n",
       "[5 rows x 43 columns]"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "joined_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Market Variables \n",
    "\n",
    "* Market Open\n",
    "* Market Close\n",
    "* Market High\n",
    "* Market Low\n",
    "* Market Volume\n",
    "\n",
    "\n",
    "Make sure you have aligned the data by date in a pandas data frame. Show the counts and the summary stats."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Open</th>\n",
       "      <th>High</th>\n",
       "      <th>Low</th>\n",
       "      <th>Close</th>\n",
       "      <th>Adj Close</th>\n",
       "      <th>Volume</th>\n",
       "      <th>ACMH</th>\n",
       "      <th>ACSH</th>\n",
       "      <th>AWND</th>\n",
       "      <th>FMTM</th>\n",
       "      <th>...</th>\n",
       "      <th>WT14</th>\n",
       "      <th>WT15</th>\n",
       "      <th>WT16</th>\n",
       "      <th>WT17</th>\n",
       "      <th>WT18</th>\n",
       "      <th>WT22</th>\n",
       "      <th>was_raining</th>\n",
       "      <th>prcp_intensity</th>\n",
       "      <th>was_snowing</th>\n",
       "      <th>snow_intensity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>4312.000000</td>\n",
       "      <td>4312.000000</td>\n",
       "      <td>4312.000000</td>\n",
       "      <td>4312.000000</td>\n",
       "      <td>4312.000000</td>\n",
       "      <td>4312.0</td>\n",
       "      <td>4312.00000</td>\n",
       "      <td>4312.000000</td>\n",
       "      <td>4312.000000</td>\n",
       "      <td>4312.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>4312.000000</td>\n",
       "      <td>4312.000000</td>\n",
       "      <td>4312.000000</td>\n",
       "      <td>4312.000000</td>\n",
       "      <td>4312.000000</td>\n",
       "      <td>4312.000000</td>\n",
       "      <td>4312.000000</td>\n",
       "      <td>4312.000000</td>\n",
       "      <td>4312.000000</td>\n",
       "      <td>4312.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>2421.235815</td>\n",
       "      <td>2421.235815</td>\n",
       "      <td>2421.235815</td>\n",
       "      <td>2421.235815</td>\n",
       "      <td>2421.235815</td>\n",
       "      <td>0.0</td>\n",
       "      <td>26.25000</td>\n",
       "      <td>26.843692</td>\n",
       "      <td>22.205009</td>\n",
       "      <td>669.627087</td>\n",
       "      <td>...</td>\n",
       "      <td>0.110390</td>\n",
       "      <td>0.006030</td>\n",
       "      <td>0.376160</td>\n",
       "      <td>0.008813</td>\n",
       "      <td>0.121289</td>\n",
       "      <td>0.000464</td>\n",
       "      <td>0.303108</td>\n",
       "      <td>0.030930</td>\n",
       "      <td>0.076531</td>\n",
       "      <td>0.006421</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>46.976401</td>\n",
       "      <td>46.976401</td>\n",
       "      <td>46.976401</td>\n",
       "      <td>46.976401</td>\n",
       "      <td>46.976401</td>\n",
       "      <td>0.0</td>\n",
       "      <td>37.15298</td>\n",
       "      <td>38.682017</td>\n",
       "      <td>24.175577</td>\n",
       "      <td>806.458088</td>\n",
       "      <td>...</td>\n",
       "      <td>0.313411</td>\n",
       "      <td>0.077426</td>\n",
       "      <td>0.484477</td>\n",
       "      <td>0.093472</td>\n",
       "      <td>0.326501</td>\n",
       "      <td>0.021534</td>\n",
       "      <td>0.459655</td>\n",
       "      <td>0.083224</td>\n",
       "      <td>0.265876</td>\n",
       "      <td>0.040880</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>2304.229980</td>\n",
       "      <td>2304.229980</td>\n",
       "      <td>2304.229980</td>\n",
       "      <td>2304.229980</td>\n",
       "      <td>2304.229980</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>2391.780029</td>\n",
       "      <td>2391.780029</td>\n",
       "      <td>2391.780029</td>\n",
       "      <td>2391.780029</td>\n",
       "      <td>2391.780029</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>2418.530029</td>\n",
       "      <td>2418.530029</td>\n",
       "      <td>2418.530029</td>\n",
       "      <td>2418.530029</td>\n",
       "      <td>2418.530029</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>20.500000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>2438.620117</td>\n",
       "      <td>2438.620117</td>\n",
       "      <td>2438.620117</td>\n",
       "      <td>2438.620117</td>\n",
       "      <td>2438.620117</td>\n",
       "      <td>0.0</td>\n",
       "      <td>60.00000</td>\n",
       "      <td>60.000000</td>\n",
       "      <td>41.000000</td>\n",
       "      <td>1450.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.020134</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>2559.689941</td>\n",
       "      <td>2559.689941</td>\n",
       "      <td>2559.689941</td>\n",
       "      <td>2559.689941</td>\n",
       "      <td>2559.689941</td>\n",
       "      <td>0.0</td>\n",
       "      <td>100.00000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>182.000000</td>\n",
       "      <td>2357.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows × 42 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              Open         High          Low        Close    Adj Close  \\\n",
       "count  4312.000000  4312.000000  4312.000000  4312.000000  4312.000000   \n",
       "mean   2421.235815  2421.235815  2421.235815  2421.235815  2421.235815   \n",
       "std      46.976401    46.976401    46.976401    46.976401    46.976401   \n",
       "min    2304.229980  2304.229980  2304.229980  2304.229980  2304.229980   \n",
       "25%    2391.780029  2391.780029  2391.780029  2391.780029  2391.780029   \n",
       "50%    2418.530029  2418.530029  2418.530029  2418.530029  2418.530029   \n",
       "75%    2438.620117  2438.620117  2438.620117  2438.620117  2438.620117   \n",
       "max    2559.689941  2559.689941  2559.689941  2559.689941  2559.689941   \n",
       "\n",
       "       Volume        ACMH         ACSH         AWND         FMTM  ...  \\\n",
       "count  4312.0  4312.00000  4312.000000  4312.000000  4312.000000  ...   \n",
       "mean      0.0    26.25000    26.843692    22.205009   669.627087  ...   \n",
       "std       0.0    37.15298    38.682017    24.175577   806.458088  ...   \n",
       "min       0.0     0.00000     0.000000     0.000000     0.000000  ...   \n",
       "25%       0.0     0.00000     0.000000     0.000000     0.000000  ...   \n",
       "50%       0.0     0.00000     0.000000    20.500000     0.000000  ...   \n",
       "75%       0.0    60.00000    60.000000    41.000000  1450.000000  ...   \n",
       "max       0.0   100.00000   100.000000   182.000000  2357.000000  ...   \n",
       "\n",
       "              WT14         WT15         WT16         WT17         WT18  \\\n",
       "count  4312.000000  4312.000000  4312.000000  4312.000000  4312.000000   \n",
       "mean      0.110390     0.006030     0.376160     0.008813     0.121289   \n",
       "std       0.313411     0.077426     0.484477     0.093472     0.326501   \n",
       "min       0.000000     0.000000     0.000000     0.000000     0.000000   \n",
       "25%       0.000000     0.000000     0.000000     0.000000     0.000000   \n",
       "50%       0.000000     0.000000     0.000000     0.000000     0.000000   \n",
       "75%       0.000000     0.000000     1.000000     0.000000     0.000000   \n",
       "max       1.000000     1.000000     1.000000     1.000000     1.000000   \n",
       "\n",
       "              WT22  was_raining  prcp_intensity  was_snowing  snow_intensity  \n",
       "count  4312.000000  4312.000000     4312.000000  4312.000000     4312.000000  \n",
       "mean      0.000464     0.303108        0.030930     0.076531        0.006421  \n",
       "std       0.021534     0.459655        0.083224     0.265876        0.040880  \n",
       "min       0.000000     0.000000        0.000000     0.000000        0.000000  \n",
       "25%       0.000000     0.000000        0.000000     0.000000        0.000000  \n",
       "50%       0.000000     0.000000        0.000000     0.000000        0.000000  \n",
       "75%       0.000000     1.000000        0.020134     0.000000        0.000000  \n",
       "max       1.000000     1.000000        1.000000     1.000000        1.000000  \n",
       "\n",
       "[8 rows x 42 columns]"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "joined_data.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "source": [
    "## Part 4: Feature Engineering\n",
    "\n",
    "Because we are going to be thinking of this in terms of a simple neural network here (like a dense neural network), extend the data by the input data actually being the past $n$ days ($n$ between 1 and 7). In other words the $X$ input should contain a lag of variables you loaded, but lagged by days from 1 through 7. In other words if it hasn't snowed in the past 7 days you will have attributes $[0,0,0,0,0,0,0]$ for yesterday and the preceeding 8 days of no snow, being \"columns\" or dimensions in your input data.\n",
    "\n",
    "One challenge is that for weekend you will not have trading days so you will need to do some data filling. After you \"fatten\" your data, should see if you need all this data. You should normalize all your input variables so that that have an approximate range between 0 and 1. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "from functools import partial\n",
    "\n",
    "def lag_function(num_days, x):\n",
    "    # fill in the code for the lag day here\n",
    "    return x\n",
    "\n",
    "lag_one_day = partial(lag_function, 1)\n",
    "joined_data[\"market_volatility_lag_one\"] = joined_data.apply(lag_one_day, axis=1)\n",
    "\n",
    "lag_two_days = partial(lag_function, 2)\n",
    "joined_data[\"market_volatility_lag_two\"] = joined_data.apply(lag_two_days, axis=1)\n",
    "\n",
    "lag_three_days = partial(lag_function, 3)\n",
    "joined_data[\"market_volatility_lag_three\"] = joined_data.apply(lag_three_days, axis=1)\n",
    "\n",
    "lag_four_days = partial(lag_function, 4)\n",
    "joined_data[\"market_volatility_lag_four\"] = joined_data.apply(lag_four_days, axis=1)\n",
    "\n",
    "lag_five_days = partial(lag_function, 5)\n",
    "joined_data[\"market_volatility_lag_five\"] = joined_data.apply(lag_five_days, axis=1)\n",
    "\n",
    "lag_six_days = partial(lag_function, 6)\n",
    "joined_data[\"market_volatility_lag_six\"] = joined_data.apply(lag_six_days, axis=1)\n",
    "\n",
    "lag_seven_days = partial(lag_function, 7)\n",
    "joined_data[\"market_volatility_lag_seven\"] = joined_data.apply(lag_seven_days, axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add the code for dealing with weekends here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add the code for normalization here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "joined_data['volatility'] = joined_data.High - joined_data.Low\n",
    "joined_data['day_of_week'] = joined_data.DATE.dt.dayofweek"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>DATE</th>\n",
       "      <th>Open</th>\n",
       "      <th>High</th>\n",
       "      <th>Low</th>\n",
       "      <th>Close</th>\n",
       "      <th>Adj Close</th>\n",
       "      <th>Volume</th>\n",
       "      <th>ACMH</th>\n",
       "      <th>ACSH</th>\n",
       "      <th>AWND</th>\n",
       "      <th>...</th>\n",
       "      <th>WT17</th>\n",
       "      <th>WT18</th>\n",
       "      <th>WT22</th>\n",
       "      <th>was_raining</th>\n",
       "      <th>prcp_intensity</th>\n",
       "      <th>was_snowing</th>\n",
       "      <th>snow_intensity</th>\n",
       "      <th>volatility</th>\n",
       "      <th>is_weekend</th>\n",
       "      <th>day_of_week</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1992-01-02</td>\n",
       "      <td>2423.179932</td>\n",
       "      <td>2423.179932</td>\n",
       "      <td>2423.179932</td>\n",
       "      <td>2423.179932</td>\n",
       "      <td>2423.179932</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1992-01-02</td>\n",
       "      <td>2423.179932</td>\n",
       "      <td>2423.179932</td>\n",
       "      <td>2423.179932</td>\n",
       "      <td>2423.179932</td>\n",
       "      <td>2423.179932</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>20</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1992-01-02</td>\n",
       "      <td>2423.179932</td>\n",
       "      <td>2423.179932</td>\n",
       "      <td>2423.179932</td>\n",
       "      <td>2423.179932</td>\n",
       "      <td>2423.179932</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1992-01-02</td>\n",
       "      <td>2423.179932</td>\n",
       "      <td>2423.179932</td>\n",
       "      <td>2423.179932</td>\n",
       "      <td>2423.179932</td>\n",
       "      <td>2423.179932</td>\n",
       "      <td>0</td>\n",
       "      <td>100</td>\n",
       "      <td>90</td>\n",
       "      <td>34</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1992-01-02</td>\n",
       "      <td>2423.179932</td>\n",
       "      <td>2423.179932</td>\n",
       "      <td>2423.179932</td>\n",
       "      <td>2423.179932</td>\n",
       "      <td>2423.179932</td>\n",
       "      <td>0</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>18</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 46 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        DATE         Open         High          Low        Close    Adj Close  \\\n",
       "0 1992-01-02  2423.179932  2423.179932  2423.179932  2423.179932  2423.179932   \n",
       "1 1992-01-02  2423.179932  2423.179932  2423.179932  2423.179932  2423.179932   \n",
       "2 1992-01-02  2423.179932  2423.179932  2423.179932  2423.179932  2423.179932   \n",
       "3 1992-01-02  2423.179932  2423.179932  2423.179932  2423.179932  2423.179932   \n",
       "4 1992-01-02  2423.179932  2423.179932  2423.179932  2423.179932  2423.179932   \n",
       "\n",
       "   Volume  ACMH  ACSH  AWND  ...  WT17  WT18  WT22  was_raining  \\\n",
       "0       0     0     0     0  ...     0     0     0            0   \n",
       "1       0     0     0    20  ...     0     0     0            0   \n",
       "2       0     0     0     0  ...     0     0     0            0   \n",
       "3       0   100    90    34  ...     0     0     0            0   \n",
       "4       0   100   100    18  ...     0     0     0            0   \n",
       "\n",
       "   prcp_intensity  was_snowing  snow_intensity  volatility  is_weekend  \\\n",
       "0             0.0            0             0.0         0.0           1   \n",
       "1             0.0            0             0.0         0.0           1   \n",
       "2             0.0            0             0.0         0.0           1   \n",
       "3             0.0            0             0.0         0.0           1   \n",
       "4             0.0            0             0.0         0.0           1   \n",
       "\n",
       "   day_of_week  \n",
       "0            3  \n",
       "1            3  \n",
       "2            3  \n",
       "3            3  \n",
       "4            3  \n",
       "\n",
       "[5 rows x 46 columns]"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "joined_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "source": [
    "## Part 5: Try out different Models and prediction!\n",
    "\n",
    "Your goal is to predict the volatility in the market, that is the Market High - Market Low your \"Y\" value. For convenience create that column. All of the other columns will help create your \"X\" variables. You can use any of the other variables as predictors. Be careful not use Market High or Market Low as \"X\" variables!\n",
    "\n",
    "Since we are doing a regression problem that means that the last neural net activation will probably be linear and the loss should be Mean Squared Error or root mean squared error or mean absolute error.\n",
    "\n",
    "Try five different models. For each model, please report mse, root mse and mean absolute error.  You can get the training history with:\n",
    "\n",
    "Record the history with:\n",
    "\n",
    "`history = model.fit(X, y, validation_split=0.1)`\n",
    "\n",
    "and get the history for your metrics with:\n",
    "\n",
    "`history.history`\n",
    "\n",
    "For more details, see this tutorial: https://machinelearningmastery.com/custom-metrics-deep-learning-keras-python/\n",
    "\n",
    "Also, please note the above tutorial shows you how to include multiple metrics with keras.\n",
    "\n",
    "Then try cross validation with the above metrics. \n",
    "\n",
    "If you've never done cross validation with keras before, please use: https://machinelearningmastery.com/evaluate-performance-deep-learning-models-keras/\n",
    "\n",
    "The above tutorial will show you how.\n",
    "\n",
    "After running cross validation for each of the metrics you should be able to answer the following questions:\n",
    "\n",
    "Is there overfitting? How do you know?\n",
    "Why do you think certain models worked well and others not as well? \n",
    "How might you improve the model?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.1.0'"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "tf.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [],
   "source": [
    "# add your model architectures here\n",
    "\n",
    "model = tf.keras.Sequential()\n",
    "\n",
    "# want to include VAE in the future\n",
    "# add Dense --> Dropout --> Squeeze --> Output\n",
    "for _ in range(3):\n",
    "    l = tf.keras.layers.Dense(64, activation='relu')\n",
    "    model.add(l)\n",
    "    dropout = tf.keras.layers.Dropout(.15)\n",
    "    model.add(dropout)\n",
    "\n",
    "squeeze = tf.keras.layers.Dense(8, activation='elu')\n",
    "model.add(squeeze)\n",
    "\n",
    "explode = tf.keras.layers.Dense(128, activation='relu')\n",
    "output = tf.keras.layers.Dense(1)\n",
    "model.add(explode)\n",
    "model.add(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [],
   "source": [
    "# implement cross validation here\n",
    "model.compile(loss='mse', metrics=['mse', 'accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X = joined_data[['ACMH', 'ACSH', 'AWND', 'was_raining', 'prcp_intensity', 'was_snowing', 'snow_intensity']].values\n",
    "y = joined_data.volatility.values\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 3234 samples\n",
      "Epoch 1/50\n",
      "3234/3234 [==============================] - 2s 737us/sample - loss: 0.0141 - mse: 0.0141 - accuracy: 0.9969\n",
      "Epoch 2/50\n",
      "3234/3234 [==============================] - 1s 329us/sample - loss: 0.0016 - mse: 0.0016 - accuracy: 1.0000\n",
      "Epoch 3/50\n",
      "3234/3234 [==============================] - 1s 267us/sample - loss: 7.3676e-04 - mse: 7.3676e-04 - accuracy: 1.0000\n",
      "Epoch 4/50\n",
      "3234/3234 [==============================] - 1s 285us/sample - loss: 6.3104e-04 - mse: 6.3104e-04 - accuracy: 1.0000\n",
      "Epoch 5/50\n",
      "3234/3234 [==============================] - 1s 350us/sample - loss: 6.4621e-04 - mse: 6.4621e-04 - accuracy: 1.0000\n",
      "Epoch 6/50\n",
      "3234/3234 [==============================] - 1s 325us/sample - loss: 5.2926e-04 - mse: 5.2926e-04 - accuracy: 1.0000\n",
      "Epoch 7/50\n",
      "3234/3234 [==============================] - 1s 314us/sample - loss: 4.6883e-04 - mse: 4.6883e-04 - accuracy: 1.0000\n",
      "Epoch 8/50\n",
      "3234/3234 [==============================] - 1s 302us/sample - loss: 3.8482e-04 - mse: 3.8482e-04 - accuracy: 1.0000\n",
      "Epoch 9/50\n",
      "3234/3234 [==============================] - 1s 291us/sample - loss: 2.7307e-04 - mse: 2.7307e-04 - accuracy: 1.0000\n",
      "Epoch 10/50\n",
      "3234/3234 [==============================] - 1s 370us/sample - loss: 2.0302e-04 - mse: 2.0302e-04 - accuracy: 1.0000\n",
      "Epoch 11/50\n",
      "3234/3234 [==============================] - 2s 625us/sample - loss: 1.2260e-04 - mse: 1.2260e-04 - accuracy: 1.0000\n",
      "Epoch 12/50\n",
      "3234/3234 [==============================] - 2s 518us/sample - loss: 3.4006e-05 - mse: 3.4006e-05 - accuracy: 1.0000\n",
      "Epoch 13/50\n",
      "3234/3234 [==============================] - 2s 510us/sample - loss: 9.3440e-06 - mse: 9.3440e-06 - accuracy: 1.0000\n",
      "Epoch 14/50\n",
      "3234/3234 [==============================] - 2s 521us/sample - loss: 4.5370e-06 - mse: 4.5370e-06 - accuracy: 1.0000\n",
      "Epoch 15/50\n",
      "3234/3234 [==============================] - 2s 653us/sample - loss: 2.0167e-06 - mse: 2.0167e-06 - accuracy: 1.0000\n",
      "Epoch 16/50\n",
      "3234/3234 [==============================] - 2s 583us/sample - loss: 3.5739e-06 - mse: 3.5739e-06 - accuracy: 1.0000\n",
      "Epoch 17/50\n",
      "3234/3234 [==============================] - 2s 604us/sample - loss: 1.1920e-06 - mse: 1.1920e-06 - accuracy: 1.0000\n",
      "Epoch 18/50\n",
      "3234/3234 [==============================] - 2s 573us/sample - loss: 1.2866e-06 - mse: 1.2866e-06 - accuracy: 1.0000\n",
      "Epoch 19/50\n",
      "3234/3234 [==============================] - 2s 509us/sample - loss: 5.8264e-07 - mse: 5.8264e-07 - accuracy: 1.0000\n",
      "Epoch 20/50\n",
      "3234/3234 [==============================] - 2s 646us/sample - loss: 1.5837e-06 - mse: 1.5837e-06 - accuracy: 1.0000\n",
      "Epoch 21/50\n",
      "3234/3234 [==============================] - 2s 523us/sample - loss: 5.0641e-07 - mse: 5.0641e-07 - accuracy: 1.0000\n",
      "Epoch 22/50\n",
      "3234/3234 [==============================] - 2s 585us/sample - loss: 6.3958e-07 - mse: 6.3958e-07 - accuracy: 1.0000\n",
      "Epoch 23/50\n",
      "3234/3234 [==============================] - 2s 635us/sample - loss: 5.1613e-07 - mse: 5.1613e-07 - accuracy: 1.0000\n",
      "Epoch 24/50\n",
      "3234/3234 [==============================] - 2s 559us/sample - loss: 4.8819e-07 - mse: 4.8819e-07 - accuracy: 1.0000\n",
      "Epoch 25/50\n",
      "3234/3234 [==============================] - 2s 555us/sample - loss: 3.9452e-07 - mse: 3.9452e-07 - accuracy: 1.0000\n",
      "Epoch 26/50\n",
      "3234/3234 [==============================] - 2s 724us/sample - loss: 2.6745e-07 - mse: 2.6745e-07 - accuracy: 1.0000\n",
      "Epoch 27/50\n",
      "3234/3234 [==============================] - 2s 660us/sample - loss: 3.4579e-07 - mse: 3.4579e-07 - accuracy: 1.0000\n",
      "Epoch 28/50\n",
      "3234/3234 [==============================] - 2s 655us/sample - loss: 3.3629e-07 - mse: 3.3629e-07 - accuracy: 1.0000\n",
      "Epoch 29/50\n",
      "3234/3234 [==============================] - 3s 790us/sample - loss: 2.5709e-07 - mse: 2.5709e-07 - accuracy: 1.0000\n",
      "Epoch 30/50\n",
      "3234/3234 [==============================] - 2s 656us/sample - loss: 5.7078e-07 - mse: 5.7078e-07 - accuracy: 1.0000\n",
      "Epoch 31/50\n",
      "3234/3234 [==============================] - 2s 498us/sample - loss: 3.7701e-07 - mse: 3.7701e-07 - accuracy: 1.0000\n",
      "Epoch 32/50\n",
      "3234/3234 [==============================] - 2s 675us/sample - loss: 2.7892e-07 - mse: 2.7892e-07 - accuracy: 1.0000\n",
      "Epoch 33/50\n",
      "3234/3234 [==============================] - 2s 549us/sample - loss: 3.4341e-07 - mse: 3.4341e-07 - accuracy: 1.0000\n",
      "Epoch 34/50\n",
      "3234/3234 [==============================] - 2s 622us/sample - loss: 3.4616e-07 - mse: 3.4616e-07 - accuracy: 1.0000\n",
      "Epoch 35/50\n",
      "3234/3234 [==============================] - 2s 630us/sample - loss: 2.5711e-07 - mse: 2.5711e-07 - accuracy: 1.0000\n",
      "Epoch 36/50\n",
      "3234/3234 [==============================] - 2s 595us/sample - loss: 2.9014e-07 - mse: 2.9014e-07 - accuracy: 1.0000\n",
      "Epoch 37/50\n",
      "3234/3234 [==============================] - 2s 629us/sample - loss: 2.8775e-07 - mse: 2.8775e-07 - accuracy: 1.0000\n",
      "Epoch 38/50\n",
      "3234/3234 [==============================] - 2s 618us/sample - loss: 2.9301e-07 - mse: 2.9301e-07 - accuracy: 1.0000\n",
      "Epoch 39/50\n",
      "3234/3234 [==============================] - 2s 676us/sample - loss: 2.6832e-07 - mse: 2.6832e-07 - accuracy: 1.0000\n",
      "Epoch 40/50\n",
      "3234/3234 [==============================] - 2s 737us/sample - loss: 2.6849e-07 - mse: 2.6849e-07 - accuracy: 1.0000\n",
      "Epoch 41/50\n",
      "3234/3234 [==============================] - 2s 724us/sample - loss: 2.6115e-07 - mse: 2.6115e-07 - accuracy: 1.0000\n",
      "Epoch 42/50\n",
      "3234/3234 [==============================] - 2s 632us/sample - loss: 2.6535e-07 - mse: 2.6535e-07 - accuracy: 1.0000\n",
      "Epoch 43/50\n",
      "3234/3234 [==============================] - 2s 579us/sample - loss: 2.6506e-07 - mse: 2.6506e-07 - accuracy: 1.0000\n",
      "Epoch 44/50\n",
      "3234/3234 [==============================] - 2s 625us/sample - loss: 4.8578e-07 - mse: 4.8578e-07 - accuracy: 1.0000\n",
      "Epoch 45/50\n",
      "3234/3234 [==============================] - 2s 617us/sample - loss: 2.8641e-07 - mse: 2.8641e-07 - accuracy: 1.0000\n",
      "Epoch 46/50\n",
      "3234/3234 [==============================] - 2s 586us/sample - loss: 2.5036e-07 - mse: 2.5036e-07 - accuracy: 1.0000\n",
      "Epoch 47/50\n",
      "3234/3234 [==============================] - 2s 728us/sample - loss: 3.2322e-07 - mse: 3.2322e-07 - accuracy: 1.0000\n",
      "Epoch 48/50\n",
      "3234/3234 [==============================] - 2s 621us/sample - loss: 3.1390e-07 - mse: 3.1390e-07 - accuracy: 1.0000\n",
      "Epoch 49/50\n",
      "3234/3234 [==============================] - 2s 687us/sample - loss: 2.5825e-07 - mse: 2.5825e-07 - accuracy: 1.0000\n",
      "Epoch 50/50\n",
      "3234/3234 [==============================] - 2s 622us/sample - loss: 2.5545e-07 - mse: 2.5545e-07 - accuracy: 1.0000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f47359c2e90>"
      ]
     },
     "execution_count": 145,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train, y_train, batch_size=16, epochs=50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "answer answer overfitting here and analysis here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1078/1078 [==============================] - 0s 306us/sample - loss: 2.0830e-07 - mse: 2.0830e-07 - accuracy: 1.0000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[2.0829531877097907e-07, 2.0829523e-07, 1.0]"
      ]
     },
     "execution_count": 146,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(X_test, y_test, batch_size=16)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Overall Conclusion\n",
    "\n",
    "Conclude with a full report here on what we know now about this problem. How well it does verses baseline, what the best Keras archtecture is, what features should be used, how the data should be cleaned etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:deep-learning-spring-20] *",
   "language": "python",
   "name": "conda-env-deep-learning-spring-20-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  },
  "nteract": {
   "version": "0.22.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
