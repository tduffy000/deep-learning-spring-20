{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this assignment we will look at a typical image based machine learning task.\n",
    "\n",
    "`@author: Thomas Duffy`\n",
    "\n",
    "## Image classification \n",
    "\n",
    "For this task the whole image is used to classify what's happening.\n",
    "\n",
    "For this specific task, we will be trying to classify COVID-19 using pneumonia x-rays.  Please note, the literature has mostly suggested CT scans are not an effective way of figuring out what type of disease you have.  This exercise is for academic purposes _only_.\n",
    "\n",
    "Steps:\n",
    "\n",
    "\n",
    "1. Download the pneumonia data.  \n",
    "\n",
    "    You can find it [here](https://www.kaggle.com/paultimothymooney/chest-xray-pneumonia). Move the folder to this directory and unzip it.  Please don't change any folder names or the below script will not work.  Also make sure the folder is in the same directory as this notebook!\n",
    "\n",
    "2. load the pneumonia data into a dataframe:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import glob\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "import tensorflow as tf\n",
    "import skimage.transform\n",
    "import skimage.color"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.1.0'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.2.4-tf'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.keras.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_training_data():\n",
    "    paths = [\n",
    "        \"chest_xray/train/NORMAL/*\",\n",
    "        \"chest_xray/train/PNEUMONIA/*\"\n",
    "    ]\n",
    "    labels = []\n",
    "    image_paths = []\n",
    "    for path in paths:\n",
    "        for im_path in glob.glob(path):\n",
    "            if path == \"chest_xray/train/NORMAL/*\":\n",
    "                labels.append(\"NORMAL\")\n",
    "            if path == \"chest_xray/train/PNEUMONIA/*\":\n",
    "                labels.append(\"PNEUMONIA\")\n",
    "            image_paths.append(im_path)\n",
    "    return image_paths, labels\n",
    "\n",
    "def load_testing_data():\n",
    "    paths = [\n",
    "        \"chest_xray/test/NORMAL/*\",\n",
    "        \"chest_xray/test/PNEUMONIA/*\"\n",
    "    ]\n",
    "    labels = []\n",
    "    image_paths = []\n",
    "    for path in paths:\n",
    "        for im_path in glob.glob(path):\n",
    "            if path == \"chest_xray/test/NORMAL/*\":\n",
    "                labels.append(\"NORMAL\")\n",
    "            if path == \"chest_xray/test/PNEUMONIA/*\":\n",
    "                labels.append(\"PNEUMONIA\")\n",
    "            image_paths.append(im_path)\n",
    "    return image_paths, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_paths, train_labels = load_training_data()\n",
    "test_paths, test_labels = load_testing_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. read the data into memory, I recommend open-cv for this:\n",
    "\n",
    "`python -m pip install opencv-python` \n",
    "\n",
    "if you don't already have it!\n",
    "\n",
    "4. resize the images to a standard size - \n",
    "\n",
    "Note: it ought to be a box.  So the width and height should be the same size."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_image_features(image_paths, shape):\n",
    "    height, width, channels = shape\n",
    "    array = np.zeros((len(image_paths), height, width, channels))\n",
    "    for i, path in enumerate(image_paths):\n",
    "        im = Image.open(path)\n",
    "        as_array = np.asarray(im)\n",
    "        if len(as_array.shape) == 2: # convert to 3 channels (required input to VGG)\n",
    "            as_array = skimage.color.gray2rgb(as_array)\n",
    "        resized = skimage.transform.resize(as_array, shape)\n",
    "        array[i,:,:] = resized\n",
    "        if (i + 1) % 500 == 0:\n",
    "            print(f'Finished loading {i+1} samples')\n",
    "    return array"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next you'll need to do the same for the labels:\n",
    "\n",
    "Note: You'll need to apply the `to_categorical` function after transforming to a numpy array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'NORMAL': 0, 'PNEUMONIA': 1}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "categorical_mapping = { label: i for i, label in enumerate(set(train_labels)) }\n",
    "categorical_mapping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def labels_to_np_array(labels, mapping):\n",
    "    return np.array([mapping[label] for label in labels])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "7. Seperate into train and test with `train_test_split` from scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5216"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# how many training samples should we get?\n",
    "len(train_paths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "IMAGE_SHAPE = (128, 128, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished loading 500 samples\n",
      "Finished loading 1000 samples\n",
      "Finished loading 1500 samples\n",
      "Finished loading 2000 samples\n",
      "Finished loading 2500 samples\n",
      "Finished loading 3000 samples\n",
      "Finished loading 3500 samples\n",
      "Finished loading 4000 samples\n",
      "Finished loading 4500 samples\n",
      "Finished loading 5000 samples\n"
     ]
    }
   ],
   "source": [
    "full_training_X = get_image_features(train_paths, IMAGE_SHAPE)\n",
    "full_training_y = labels_to_np_array(train_labels, categorical_mapping)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5216, 128, 128, 3)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "full_training_X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "full_training_X.shape[0] == full_training_y.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "SEED = 42"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "TEST_SET_SIZE = .2\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    full_training_X, full_training_y, test_size=TEST_SET_SIZE, random_state=SEED\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# sanity check, what does one image look like?\n",
    "_ = plt.imshow(X_train[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# what's the class proportion?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "8. Make the last four layers of VGG16 with imagenet weights trainable and then retrain the model.\n",
    "\n",
    "To understand how to do this, please see the following tutorial:\n",
    "\n",
    "https://www.learnopencv.com/keras-tutorial-fine-tuning-using-pre-trained-models/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.keras.backend.clear_session()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "vgg_conv = tf.keras.applications.VGG16(weights='imagenet', include_top=False, input_shape=IMAGE_SHAPE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Is InputLayer traininable? False\n",
      "Is Conv2D traininable? False\n",
      "Is Conv2D traininable? False\n",
      "Is MaxPooling2D traininable? False\n",
      "Is Conv2D traininable? False\n",
      "Is Conv2D traininable? False\n",
      "Is MaxPooling2D traininable? False\n",
      "Is Conv2D traininable? False\n",
      "Is Conv2D traininable? False\n",
      "Is Conv2D traininable? False\n",
      "Is MaxPooling2D traininable? False\n",
      "Is Conv2D traininable? False\n",
      "Is Conv2D traininable? False\n",
      "Is Conv2D traininable? False\n",
      "Is MaxPooling2D traininable? False\n",
      "Is Conv2D traininable? True\n",
      "Is Conv2D traininable? True\n",
      "Is Conv2D traininable? True\n",
      "Is MaxPooling2D traininable? True\n"
     ]
    }
   ],
   "source": [
    "for layer in vgg_conv.layers[:-4]:\n",
    "    layer.trainable = False\n",
    "for layer in vgg_conv.layers:\n",
    "    print(f'Is {layer.__class__.__name__} traininable? {layer.trainable}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "vgg16 (Model)                (None, 4, 4, 512)         14714688  \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 8192)              0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 1024)              8389632   \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 1024)              0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 2)                 2050      \n",
      "=================================================================\n",
      "Total params: 23,106,370\n",
      "Trainable params: 15,471,106\n",
      "Non-trainable params: 7,635,264\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = tf.keras.models.Sequential()\n",
    "\n",
    "model.add(vgg_conv)\n",
    "\n",
    "model.add(tf.keras.layers.Flatten())\n",
    "model.add(tf.keras.layers.Dense(1024, activation='relu'))\n",
    "model.add(tf.keras.layers.Dropout(0.5))\n",
    "model.add(tf.keras.layers.Dense(2, activation='softmax'))\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile('adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "EPOCHS, BATCH_SIZE = 5, 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 3337 samples, validate on 835 samples\n",
      "Epoch 1/5\n",
      "3337/3337 [==============================] - 251s 75ms/sample - loss: 0.4149 - accuracy: 0.8421 - val_loss: 0.1064 - val_accuracy: 0.9617\n",
      "Epoch 2/5\n",
      "3337/3337 [==============================] - 263s 79ms/sample - loss: 0.1003 - accuracy: 0.9670 - val_loss: 0.0676 - val_accuracy: 0.9737\n",
      "Epoch 3/5\n",
      "3337/3337 [==============================] - 257s 77ms/sample - loss: 0.0539 - accuracy: 0.9808 - val_loss: 0.2894 - val_accuracy: 0.8970\n",
      "Epoch 4/5\n",
      "3337/3337 [==============================] - 256s 77ms/sample - loss: 0.0429 - accuracy: 0.9838 - val_loss: 0.1013 - val_accuracy: 0.9701\n",
      "Epoch 5/5\n",
      "3337/3337 [==============================] - 257s 77ms/sample - loss: 0.0280 - accuracy: 0.9892 - val_loss: 0.0870 - val_accuracy: 0.9749\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f681ab44090>"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train, y_train, epochs=EPOCHS, batch_size=BATCH_SIZE, validation_split=0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "8. Check your score with classification_report from scikit-learn\n",
    "\n",
    "Now that you've trained your model, call `model.predict` to get the predicted values for classification.  \n",
    "Then compare your predicted values with y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.93      0.96       287\n",
      "           1       0.98      0.99      0.98       757\n",
      "\n",
      "    accuracy                           0.98      1044\n",
      "   macro avg       0.98      0.96      0.97      1044\n",
      "weighted avg       0.98      0.98      0.98      1044\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "\n",
    "y_pred = model.predict_classes(X_test)\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "9. Data augmentation\n",
    "\n",
    "Now that you have a classifier, let's see if data augmentation improves things!  \n",
    "\n",
    "You can use the `ImageDataGenerator` that comes with keras.  Here's how to import it:\n",
    "\n",
    "`from tensorflow.keras.preprocessing.image import ImageDataGenerator`\n",
    "\n",
    "Here's the documentation: https://keras.io/preprocessing/image/\n",
    "\n",
    "Here's an example of it getting used in the wild, in case you get stuck:\n",
    "\n",
    "https://www.pyimagesearch.com/2020/03/16/detecting-covid-19-in-x-ray-images-with-keras-tensorflow-and-deep-learning/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_gen = tf.keras.preprocessing.image.ImageDataGenerator(\n",
    "    featurewise_center=True,\n",
    "    featurewise_std_normalization=True,\n",
    "    rotation_range=25,\n",
    "    width_shift_range=0.2,\n",
    "    height_shift_range=0.2,\n",
    "    horizontal_flip=True,\n",
    "    zoom_range=0.2,\n",
    "    validation_split=0.2\n",
    ")\n",
    "\n",
    "train_gen.fit(X_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "10. retrain your classifier\n",
    "\n",
    "Now that you have augmented training data, please retrain your classifier.  The code should basically be the same."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "vgg16 (Model)                (None, 4, 4, 512)         14714688  \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 8192)              0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 1024)              8389632   \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 1024)              0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 2)                 2050      \n",
      "=================================================================\n",
      "Total params: 23,106,370\n",
      "Trainable params: 15,471,106\n",
      "Non-trainable params: 7,635,264\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "augmented_model = tf.keras.models.Sequential()\n",
    "\n",
    "augmented_model.add(vgg_conv)\n",
    "\n",
    "augmented_model.add(tf.keras.layers.Flatten())\n",
    "augmented_model.add(tf.keras.layers.Dense(1024, activation='relu'))\n",
    "augmented_model.add(tf.keras.layers.Dropout(0.5))\n",
    "augmented_model.add(tf.keras.layers.Dense(2, activation='softmax'))\n",
    "\n",
    "augmented_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "augmented_model.compile('adam', loss='categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "Train for 104.0 steps, validate for 26.0 steps\n",
      "Epoch 1/5\n",
      "104/104 [==============================] - 290s 3s/step - loss: 1167037966.7979 - accuracy: 0.5018 - val_loss: 246794318.7692 - val_accuracy: 0.0000e+00\n",
      "Epoch 2/5\n",
      "104/104 [==============================] - 302s 3s/step - loss: 26628495420.0364 - accuracy: 0.5064 - val_loss: 24828910985.8462 - val_accuracy: 1.0000\n",
      "Epoch 3/5\n",
      "104/104 [==============================] - 302s 3s/step - loss: 130734932957.9404 - accuracy: 0.5079 - val_loss: 37757608566.1538 - val_accuracy: 0.0000e+00\n",
      "Epoch 4/5\n",
      "104/104 [==============================] - 314s 3s/step - loss: 238956677773.3564 - accuracy: 0.4921 - val_loss: 359790946146.4615 - val_accuracy: 1.0000\n",
      "Epoch 5/5\n",
      "104/104 [==============================] - 311s 3s/step - loss: 376518199594.6128 - accuracy: 0.5057 - val_loss: 163924531357.5385 - val_accuracy: 0.0000e+00\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f6740502b50>"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "augmented_model.fit(\n",
    "        train_gen.flow(X_train, y_train, batch_size=BATCH_SIZE, subset='training'),\n",
    "        steps_per_epoch = (X_train.shape[0] * (1 - 0.2)) // BATCH_SIZE,\n",
    "        epochs=EPOCHS,\n",
    "        verbose=1,\n",
    "        validation_data=train_gen.flow(X_train, y_train, batch_size=BATCH_SIZE, subset='validation'),\n",
    "        validation_steps=(X_train.shape[0] * 0.2) // BATCH_SIZE\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "11. re-evaluate your classifier\n",
    "\n",
    "Now that you've augmented the data, please re-evaluate your classifer.  Use classification report like before."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00       287\n",
      "           1       0.73      1.00      0.84       757\n",
      "\n",
      "    accuracy                           0.73      1044\n",
      "   macro avg       0.36      0.50      0.42      1044\n",
      "weighted avg       0.53      0.73      0.61      1044\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/thomas/miniconda3/envs/deep-learning-spring-20/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "\n",
    "y_pred = augmented_model.predict_classes(X_test)\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "12. Evaluate the difference with data augmentation and without:\n",
    "\n",
    "Did things improve?  Did they stay the same?  Did they get worse?  Please try to come up with an explanation of why you got the results you did."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Explanation of results go here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "13. Getting COVID19 data\n",
    "\n",
    "Now that you have a trained classifier with pneumonia, we are going to use this with COVID data.  \n",
    "\n",
    "Clone this repo:\n",
    "\n",
    "https://github.com/ieee8023/covid-chestxray-dataset\n",
    "\n",
    "use the clone command: `git clone [REPO]`\n",
    "\n",
    "to get the data locally.  \n",
    "\n",
    "Make sure to run this command in the same folder as this jupyter notebook."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "14. Read the data into memory\n",
    "\n",
    "The set up for this data repository is a little different.  Please use the following code to read the data into memory:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "def get_covid19():\n",
    "    base = \"covid-chestxray-dataset/\"\n",
    "    metadata = pd.read_csv(base+\"metadata.csv\")\n",
    "    labels = []\n",
    "    image_paths = []\n",
    "    for index, row in metadata.iterrows():\n",
    "        labels.append(row[\"finding\"])\n",
    "        image_paths.append(base+row[\"filename\"])\n",
    "    return labels, image_paths\n",
    "\n",
    "labels, covid_image_paths = get_covid19()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "15. preprocess images\n",
    "\n",
    "you'll need to run the following functions on this data:\n",
    "\n",
    "1. load_images\n",
    "2. resize_images\n",
    "3. greyscale_images\n",
    "4. features_to_np_array\n",
    "5. labels_to_np_array\n",
    "\n",
    "Make sure to run each of those functions in order!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add your function calls to covid_image_paths here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "16. Strip out labels other than 'No Finding' and 'COVID-19' from the dataset\n",
    "\n",
    "There are two straight forward ways to do this:\n",
    "\n",
    "1) use a for-loop and keep track of indices\n",
    "\n",
    "2) read labels and features into a dataframe and then filter to those two label types.  Your choice!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# label reduction code goes here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "17. Predict on the new images\n",
    "\n",
    "Here you'll use the classifier you trained on just pneumonia/not pneumonia to try and classify COVID-19 and no finding.  You'll use the pneumonia/not pneumonia classifier as a featurizer to do this.\n",
    "\n",
    "Much of the code has been written, you'll just need to supply your trained classifier as input.\n",
    "\n",
    "Please predict the labels from the classifier.  Then run `classification_report` to see how well your classifier did."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#prediction code goes here\n",
    "\n",
    "import cv2\n",
    "import numpy as np\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report\n",
    "import glob\n",
    "import code\n",
    "\n",
    "def extract_features_covid(model, width, height):\n",
    "    base = \"covid-chestxray-dataset/\"\n",
    "    metadata = pd.read_csv(base+\"metadata.csv\")\n",
    "    labels = []\n",
    "    image_paths = []\n",
    "    for index, row in metadata.iterrows():\n",
    "        if row[\"finding\"] == \"COVID-19\":\n",
    "            labels.append(\"COVID\")\n",
    "            image_paths.append(base+row[\"filename\"])\n",
    "            im = cv2.imread(im_path)\n",
    "            im = cv2.resize(im, (width, height))\n",
    "            features = model.predict(img)\n",
    "            features_np = np.array(features)\n",
    "            feature_list.append(features_np.flatten())\n",
    "\n",
    "    return np.array(feature_list), labels\n",
    "\n",
    "def extract_features_not_covid(model, width, height):\n",
    "    feature_list = []\n",
    "    labels = []\n",
    "    paths = [\n",
    "        \"chest_xray/test/NORMAL/*\",\n",
    "        \"chest_xray/test/PNEUMONIA/*\",\n",
    "        \"chest_xray/train/NORMAL/*\",\n",
    "        \"chest_xray/train/PNEUMONIA/*\"\n",
    "        \n",
    "    ]\n",
    "    for path in paths:\n",
    "        for im_path in glob.glob(path):\n",
    "            if path == \"chest_xray/train/NORMAL/*\":\n",
    "                labels.append(\"CLEAR TRAIN\")\n",
    "            if path == \"chest_xray/test/NORMAL/*\":\n",
    "                labels.append(\"CLEAR TEST\")\n",
    "            if path == \"chest_xray/train/PNEUMONIA/*\":\n",
    "                labels.append(\"PNEUMONIA\")\n",
    "            im = cv2.imread(im_path)\n",
    "            im = cv2.resize(im, (width, height))\n",
    "            features = model.predict(img)\n",
    "            features_np = np.array(features)\n",
    "            feature_list.append(features_np.flatten())\n",
    "\n",
    "    return np.array(feature_list), labels\n",
    "\n",
    "# please make a copy of your tuned model and save it to variable:\n",
    "# untuned_model = [YOUR MODEL NAME GOES HERE]\n",
    "\n",
    "# please specify the width and height you used for the image preprocessing\n",
    "# width = [YOUR WIDTH GOES HERE]\n",
    "# height = [YOUR HEIGHT GOES HERE]\n",
    "\n",
    "covid_features, covid_labels = extract_features_covid(untuned_model, width, height)\n",
    "non_covid_features, non_covid_labels = extract_features_not_covid(untuned_model, width, height)\n",
    "features = covid_features + non_covid_features\n",
    "labels = covid_labels + non_covid_labels\n",
    "X_train = []\n",
    "y_train = []\n",
    "X_test = []\n",
    "y_test = []\n",
    "for index, label in enumerate(labels):\n",
    "    if label == \"CLEAR TRAIN\":\n",
    "        X_train.append(features[index])\n",
    "        y_train.append(0)\n",
    "    if label == \"PNEUMONIA\":\n",
    "        X_train.append(features[index])\n",
    "        y_train.append(1)\n",
    "    if label == \"COVID\":\n",
    "        X_test.append(features[index])\n",
    "        y_test.append(1)\n",
    "    if label == \"CLEAR TEST\":\n",
    "        X_test.append(features[index])\n",
    "        y_test.append(0)\n",
    "\n",
    "logit_clf = LogisticRegression()\n",
    "logit_clf.fit(X_train, y_train)\n",
    "y_pred = logit_clf.predict(X_test)\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "18. Compare and contrast how the classifier did on Pneumonia versus COVID-19\n",
    "\n",
    "Did it do as well?  Worse?  About the same?  What conclusions can you draw?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Add your answers here!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we've looked at a bunch of base cases, let's see if we can improve things by changing the model architecture.  We'll do this with a bunch of discrete steps\n",
    "\n",
    "1. Change the number of trainable layers\n",
    "\n",
    "Here you will make more of the layers trainable.  For this we are going to use cross validation to try and figure out which the optimal number of trainable layers.  Please us from the last 6 layers to one layer.  So your range should be:\n",
    "\n",
    "```\n",
    "trainable_range = [-6, -5, -4, -3, -2, -1]\n",
    "```\n",
    "\n",
    "Also, your X and y data should be the pneumonia data only.  Since that's what we trained on.  We should not assume we have access to the COVID data, except for testing, which will do later on.\n",
    "\n",
    "Here's a blog post detailing how to set this up: https://machinelearningmastery.com/grid-search-hyperparameters-deep-learning-models-python-keras/\n",
    "\n",
    "Note you'll need to set the number of trainable layers inside of `model_create` in order to make this tunable.  \n",
    "\n",
    "Please report mean and standard deviation for accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cross validation code goes here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Analyze your results\n",
    "\n",
    "Do you think that changing the number of tunable layers matters?  Does it improve classification accuracy enough to warrant changing the number of tunable layers?  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Analysis and explanation go here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Tune over a layer activation function\n",
    "\n",
    "Please set the number of tunable layers to 4 again.\n",
    "\n",
    "Now we are going to make the layer activation tunable.  \n",
    "\n",
    "To do this, please change the model_create function so that each layer has it's own tunable activation function.  Then run your new cross validation code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cross validation code goes here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. Analyze your results\n",
    "\n",
    "Does your choice of activation function matter?  When does the activation function perform best?  \n",
    "\n",
    "Things to consider:\n",
    "\n",
    "* Specifically does choosing the same activation function for all of the layers do best? \n",
    "* Does choosing different activation functions for each of the layers do best?\n",
    "* Are they all within the same approximate accuracy range?\n",
    "* do things vary wildly?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Analysis and explanation go here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. Tune over more hyperparameters\n",
    "\n",
    "Now that we've tuned the activation functions, let's try tuning more parameters.  This time add tuning for the following parameters:\n",
    "\n",
    "* number of neurons per layer\n",
    "* weight initialization\n",
    "* optimizer\n",
    "* weight constraint\n",
    "* activation function\n",
    "* learning rate\n",
    "\n",
    "Here is a great post on the range of values you should consider: https://www.wandb.com/articles/fundamentals-of-neural-networks\n",
    "\n",
    "Here is some code that is also useful: https://www.kaggle.com/lavanyashukla01/training-a-neural-network-start-here\n",
    "\n",
    "for understanding this practically."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cross validation code goes here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5. Tune over data augmentation\n",
    "\n",
    "Here you'll take the best hyperparameters from your neural network, with 4 trainable layers, and then add them to a pipeline.  We will then tune over data augmentation parameters.  Report out your mean and standard deviation of accuracy.\n",
    "\n",
    "Here we will create a scikit-learn pipline:\n",
    "\n",
    "https://scikit-learn.org/stable/modules/generated/sklearn.pipeline.Pipeline.html\n",
    "\n",
    "If you need an example with gridsearch and pipeline:\n",
    "\n",
    "https://scikit-learn.org/stable/tutorial/statistical_inference/putting_together.html\n",
    "\n",
    "As a reminder, here is the documentation for data augmentation:\n",
    "\n",
    "https://keras.io/preprocessing/image/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#cross validation code goes here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "6. Analyze your results\n",
    "\n",
    "Now that you've tuned over model parameters and preprocessing, what has a bigger impact?  Why do you think that might be the case?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Analysis and explanation goes here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "7. Using your best model and preprocessing to train a new model\n",
    "\n",
    "Now you should select the best hyperparameters for the neural network and the best hyperparameters for the preprocesser and then combine them into a scikit-learn pipeline.  Next train a classifier with these new tuned hyperparameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#classifer generation code goes here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "8. Let's see if things improved - time for `classification_report`\n",
    "\n",
    "Now that you've tuned your model, let's see how well it does on our test set!  First call predict on the test data to get a prediction.  Then use `classification_report` to see how well the model does."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prediction code goes here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "9. Analsis and comparison\n",
    "\n",
    "Now that you've seen how well your classifier does when it's been tuned, compare this with your previous model, that was untuned.  Are the precision, recall and f1-scores substantially different?  Why or why not?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Analysis and explanation goes here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "10. Prediction on COVID binary classification task with tuned model\n",
    "\n",
    "Now you'll use your tuned classifier to try and predict on the binary COVID19 case.  Please change the model to your tuned model!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#prediction code goes here\n",
    "\n",
    "import cv2\n",
    "import numpy as np\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report\n",
    "import glob\n",
    "import code\n",
    "\n",
    "def extract_features_covid(model, width, height):\n",
    "    base = \"covid-chestxray-dataset/\"\n",
    "    metadata = pd.read_csv(base+\"metadata.csv\")\n",
    "    labels = []\n",
    "    image_paths = []\n",
    "    for index, row in metadata.iterrows():\n",
    "        if row[\"finding\"] == \"COVID-19\":\n",
    "            labels.append(\"COVID\")\n",
    "            image_paths.append(base+row[\"filename\"])\n",
    "            im = cv2.imread(im_path)\n",
    "            im = cv2.resize(im, (width, height))\n",
    "            features = model.predict(img)\n",
    "            features_np = np.array(features)\n",
    "            feature_list.append(features_np.flatten())\n",
    "\n",
    "    return np.array(feature_list), labels\n",
    "\n",
    "def extract_features_not_covid(model, width, height):\n",
    "    feature_list = []\n",
    "    labels = []\n",
    "    paths = [\n",
    "        \"chest_xray/test/NORMAL/*\",\n",
    "        \"chest_xray/test/PNEUMONIA/*\",\n",
    "        \"chest_xray/train/NORMAL/*\",\n",
    "        \"chest_xray/train/PNEUMONIA/*\"\n",
    "        \n",
    "    ]\n",
    "    for path in paths:\n",
    "        for im_path in glob.glob(path):\n",
    "            if path == \"chest_xray/train/NORMAL/*\":\n",
    "                labels.append(\"CLEAR TRAIN\")\n",
    "            if path == \"chest_xray/test/NORMAL/*\":\n",
    "                labels.append(\"CLEAR TEST\")\n",
    "            if path == \"chest_xray/train/PNEUMONIA/*\":\n",
    "                labels.append(\"PNEUMONIA\")\n",
    "            im = cv2.imread(im_path)\n",
    "            im = cv2.resize(im, (width, height))\n",
    "            features = model.predict(img)\n",
    "            features_np = np.array(features)\n",
    "            feature_list.append(features_np.flatten())\n",
    "\n",
    "    return np.array(feature_list), labels\n",
    "\n",
    "# please make a copy of your tuned model and save it to variable:\n",
    "# tuned_model = [YOUR MODEL NAME GOES HERE]\n",
    "\n",
    "# please specify the width and height you used for the image preprocessing\n",
    "# width = [YOUR WIDTH GOES HERE]\n",
    "# height = [YOUR HEIGHT GOES HERE]\n",
    "\n",
    "covid_features, covid_labels = extract_features_covid(tuned_model, width, height)\n",
    "non_covid_features, non_covid_labels = extract_features_not_covid(tuned_model, width, height)\n",
    "features = covid_features + non_covid_features\n",
    "labels = covid_labels + non_covid_labels\n",
    "X_train = []\n",
    "y_train = []\n",
    "X_test = []\n",
    "y_test = []\n",
    "for index, label in enumerate(labels):\n",
    "    if label == \"CLEAR TRAIN\":\n",
    "        X_train.append(features[index])\n",
    "        y_train.append(0)\n",
    "    if label == \"PNEUMONIA\":\n",
    "        X_train.append(features[index])\n",
    "        y_train.append(1)\n",
    "    if label == \"COVID\":\n",
    "        X_test.append(features[index])\n",
    "        y_test.append(1)\n",
    "    if label == \"CLEAR TEST\":\n",
    "        X_test.append(features[index])\n",
    "        y_test.append(0)\n",
    "\n",
    "logit_clf = LogisticRegression()\n",
    "logit_clf.fit(X_train, y_train)\n",
    "y_pred = logit_clf.predict(X_test)\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "11. Analyze your results\n",
    "\n",
    "Now that you've seen the results of your tuned model, compare those with the results of the untuned model.  Did things get better? Worse?  Why do you think this may or may not be the case?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Analysis of your results goes here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:deep-learning-spring-20] *",
   "language": "python",
   "name": "conda-env-deep-learning-spring-20-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
